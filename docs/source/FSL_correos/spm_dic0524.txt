Dear SPM team

I have a query about application of random field theory to EEG data structured as topography × time 
× frequency (4D). While this is not natively supported in SPM, I am exploring the possibility of 
extending SPM's RFT framework to estimate smoothness across this 4D structure. I have a few 
questions about whether this extension is theoretically and practically valid.

In more detail: I aim to implement smoothness estimation across the full 4D dataset to allow 
RFT-based family-wise error (FWE) correction over all four dimensions simultaneously. Currently, I 
am treating frequency as an independent condition and applying 3D RFT corrections (topography × 
time) for each frequency separately, but this is suboptimal as it does not account for spectral 
dependencies. I would like to adapt SPM's smoothness estimation framework (e.g., 
spm_est_smoothness.m) to estimate smoothness across the 4D field and apply corresponding 
corrections using spm_P_RF.m.

Firstly, from a theoretical standpoint: Are there any in-principle reasons why extending smoothness 
estimation to 4D (topography × time × frequency) is not valid or not recommended? My assumption is 
that the extension is valid under RFT if smoothness is well-defined and estimable across all four 
dimensions. However, I recognise that spectral dependencies may introduce challenges compared to 
the standard spatial and temporal dimensions. Would extending RFT correction to 4D require any 
significant re-evaluation of SPM’s assumptions, such as isotropy, stationarity, or smoothness 
homogeneity? Is there a risk that such an extension might overestimate or underestimate statistical 
power due to inherent differences in the spectral dimension compared to spatial or temporal 
dimensions?

Secondly, can spm_est_smoothness.m be adapted to estimate and utilise 4D smoothness? I was thinking 
of extending the FWHM calculation to include the frequency dimension, possibly requiring 
adjustments to the residual field structure. I'm not sure if any adjustment are needed to 
spm_P_RF.m as it seems to be agnostic to data dimensionality. This would all be from custom 
scripts/functions of course since SPM would not natively handle this.

There are of course non-parametric alternatives available (e.g., permutation-based clustering in 
FieldTrip) but there are advantages to the parametric framework and so I was wondering if you are 
aware of whether the necessary assumptions had already been explored for implementing the above?

I appreciate your time and any insights you might have. Thank you for your guidance!

Best wishes
Chris Brown
University of Liverpool

Hi Everyone

Instats is offering a new seminar on Survival Analysis for Social and Health Science, running Dec 6 
with professor Kevin Grimm. This one-day workshop provides a comprehensive introduction to survival 
analysis, focusing on its application in social and health sciences. Participants will gain 
hands-on experience with R, SAS, and Mplus, learning to analyze survival data effectively. Topics 
include how to manage survival data, the assumptions and limitations of different survival models, 
and applying these methods to empirical data. The skills gained from this workshop will enhance 
participants' ability to conduct rigorous and impactful research, ultimately contributing to their 
academic and professional growth.

Sign up today to secure your spot in this unique event - and please feel free to tell your 
colleagues and students.


Best wishes

Michael Zyphur
Director
Institute for Statistical and Data Science
instats.org

Dear List,

Postdoctoral Research Fellow (deadline January):

We are looking for someone passionate about computational psychiatry and with expertise in 
multi-session computational modelling of reward tasks and in multi-level modelling (ambulatory/EMA 
data). There will also be an opportunity to contribute to model-based fMRI analyses.

The role involves joining an exciting three-year grant-funded project, Integrating circadian 
dysfunction and reward sensitivity in bipolar disorder, working alongside our collaborators at UC 
Berkeley, Northwestern, Yale and Swinburne Tech (Melbourne). Across animal and human work, the 
grant tests a novel hypothesis that weakened circadian signals in bipolar disorder lead to 
dysregulated reward processes in the evening (a failure to power down). 

Closes end of Jan 
https://www.ucl.ac.uk/work-at-ucl/search-ucl-jobs/details?jobId=29529&jobTitle=Research+Fellow



Dear All, 
 
I have been trying to set up the design for an experiment where faces are presented to participants 
every 750ms for 200ms. In the middle of a run, there is a longer break of approximately 10s where 
nothing is presented. I added the EV with a 3 column text file with all the onsets in the first 
column, all zeros in the second and all ones in the third. 
 
Here is what I expected the design to look like when using a Double Gamma on the left, next to the 
same participant but without any convolution: 

 
However, for some of the participants the convolved design, here on the left, looks off: 

 
When I model the same onsets in SPM, the design looks completely fine and similar to the 
participant on the top. 
 
Does anyone have an idea what's happening here? 
 
Best, 
Irene


Hi Chris, 

This is a very interesting project. 

With regards to your questions

"Are there any in-principle reasons why extending smoothness estimation to 4D (topography × time × 
frequency) is not valid or not recommended?"
No
"Would extending RFT correction to 4D require any significant re-evaluation of SPM’s assumptions, 
such as isotropy, stationarity, or smoothness homogeneity?"
None that I can think of
"Is there a risk that such an extension might overestimate or underestimate statistical power due 
to inherent differences in the spectral dimension compared to spatial or temporal dimensions?"
In general random field theory becomes more conservative as a function of number of dimensions 
because the threshold at which RFT produces valid control of FWE becomes higher as the number of 
dimensions increases. It could also become more liberal if used at a threshold below which the high 
threshold assumption holds. So no clear answer here.
"can spm_est_smoothness.m be adapted to estimate and utilise 4D smoothness?"
This could be very painful (but not impossible) as the function is so deeply tied to the estimation 
of the linear model. We've been considering internally  how to create a more modular  RFT and this 
is a big hurdle. 
"I'm not sure if any adjustment are needed to spm_P_RF.m as it seems to be agnostic to data 
dimensionality."
It is not agnostic to dimensionality. The Euler characteristic density changes as a function of 
dimensionality so either the 4th order density needs to be included or the code needs to be 
rewritten for the N-dimensional case
"I was wondering if you are aware of whether the necessary assumptions had already been explored 
for implementing the above?"
I think about this all the time but can't ever find the time to do it. It would definitely be  a 
big undertaking for the brave soul who tackled it but certainly possible from a theoretical 
perspective. 
best,

Tim Tierney

Principal Investigator
Department of Imaging Neuroscience
UCL Queen Square Institute of Neurology
12 Queen Square, London,WC1N 3AR
From: SPM (Statistical Parametric Mapping) <SPM@JISCMAIL.AC.UK> on behalf of Christopher Andrew 
Brown <cab79@LIVERPOOL.AC.UK>
Sent: 04 December 2024 08:17
To: SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>
Subject: [SPM] EEG time-frequency and RFT
 
⚠ Caution: External sender


Dear SPM team

I have a query about application of random field theory to EEG data structured as topography × time 
× frequency (4D). While this is not natively supported in SPM, I am exploring the possibility of 
extending SPM's RFT framework to estimate smoothness across this 4D structure. I have a few 
questions about whether this extension is theoretically and practically valid.

In more detail: I aim to implement smoothness estimation across the full 4D dataset to allow 
RFT-based family-wise error (FWE) correction over all four dimensions simultaneously. Currently, I 
am treating frequency as an independent condition and applying 3D RFT corrections (topography × 
time) for each frequency separately, but this is suboptimal as it does not account for spectral 
dependencies. I would like to adapt SPM's smoothness estimation framework (e.g., 
spm_est_smoothness.m) to estimate smoothness across the 4D field and apply corresponding 
corrections using spm_P_RF.m.

Firstly, from a theoretical standpoint: Are there any in-principle reasons why extending smoothness 
estimation to 4D (topography × time × frequency) is not valid or not recommended? My assumption is 
that the extension is valid under RFT if smoothness is well-defined and estimable across all four 
dimensions. However, I recognise that spectral dependencies may introduce challenges compared to 
the standard spatial and temporal dimensions. Would extending RFT correction to 4D require any 
significant re-evaluation of SPM’s assumptions, such as isotropy, stationarity, or smoothness 
homogeneity? Is there a risk that such an extension might overestimate or underestimate statistical 
power due to inherent differences in the spectral dimension compared to spatial or temporal 
dimensions?

Secondly, can spm_est_smoothness.m be adapted to estimate and utilise 4D smoothness? I was thinking 
of extending the FWHM calculation to include the frequency dimension, possibly requiring 
adjustments to the residual field structure. I'm not sure if any adjustment are needed to 
spm_P_RF.m as it seems to be agnostic to data dimensionality. This would all be from custom 
scripts/functions of course since SPM would not natively handle this.

There are of course non-parametric alternatives available (e.g., permutation-based clustering in 
FieldTrip) but there are advantages to the parametric framework and so I was wondering if you are 
aware of whether the necessary assumptions had already been explored for implementing the above?

I appreciate your time and any insights you might have. Thank you for your guidance!

Best wishes
Chris Brown
University of Liverpool

We have a fully-funded 4-year PhD position at The University of Manchester looking at modelling the 
effects of dopaminergic neuromodulation on brain state and function. Please see full details here:

 

https://www.findaphd.com/phds/project/bicentenary-modelling-the-effects-of-dopaminergic-neuromodulation-on-brain-state-and-function/?p178893

 

Application deadline is January 10th 2025, the call is open to UK and international students. 
Further details on the programme can be found here: 
https://www.bmh.manchester.ac.uk/study/research/funding-fees/funded-programmes/bicentenary-studentships/ 
and interested candidates may contact the lead supervisor directly via email 
(darya.frank@manchester.ac.uk)

 

 

Darya Frank, PhD FHEA

Royal Society University Research Fellow

Lecturer in Cognitive Neuroscience

Division of Psychology, Communication, and Human Neuroscience | Faculty of Biology, Medicine, and 
Health | The University of Manchester

https://research.manchester.ac.uk/en/persons/darya.frank

Dear Gregor,

On Sat, 30 Nov 2024 20:39:49 +0000, Domes, Gregor <domes@UNI-TRIER.DE> wrote:

>Dear CAT12 experts!
>
>I have some questions:
>
>a) In a simple group comparison, I analyzed regional volumes using VBM and cortical thickness 
using SBM (n=20 vs. n=20). The effects are an order of magnitude stronger in the VBM analyses (many 
cluster with p<.05 corr.), but are also partly found with regard to cortical thickness in some 
cortical regions (p<.001 uncorr.). I wonder whether this could simply be an effect of different 
(statistical) sensitivity of the two procedures, or rather means that less strong effects were 
observed with regard to cortical thickness because there were simply no differences here. Is it 
conceivable that the volume of gray matter in the cortex is reduced without a decrease in cortical 
thickness?

Cortical thickness is the better biological measure, while grey matter volume is more sensitive. 
This is because surface reconstruction is more susceptible to image quality problems and thickness 
is estimated in the sub-millimeter range, whereas images have a spatial resolution of about 1 mm.

>b) The effects of the VBM ROI analysis appear even stronger than those of the voxel-wise analysis. 
I assume that the ROI analysis is simply more sensitive, right?
ROI analysis requires less correction for multiple comparisons, since the number of regions is much 
smaller than the number of voxels. However, ROI analysis my be less sensitive if only a part of the 
ROI is affected.

>
>c) In the voxel-wise VBM, I included the TIV as a covariate because there are differences between 
the groups. I understood the explanations in the manual to mean that all covariates are then also 
taken into account in the ROI analysis. Is that correct? But the exported ROI volumes are raw 
values and not the residuals, or have I misunderstood something?
In the analysis TIV is automatically considered to be compatible to the stat. model that is used 
for VBM. However, extracting ROI volumes is without correction to have native values that can be 
used in your own stat. analysis and you have to additionally use TIV correction.

>
>Maybe some of you have similar questions or even answers...
Maybe in the FAQ?
https://neuro-jena.github.io/cat12-help/#faq

Best, Christian
>
>Many thanks and best regards!
>Gregor
>

Dear Gregor,

this is often asked:
https://neuro-jena.github.io/cat12-help/#faq
Manual Computational Anatomy Toolbox CAT12 - GitHub Pages
General notes and options for statistical models Please note that when using "Basic Models" in the 
CAT12 GUI, some unnecessary options have been removed compared to the "Basic Models" in SPM12, and 
some useful options have been added. We therefore strongly recommend preferring to use the models 
in CAT12, which offer some advantages especially when defining longitudinal designs.
neuro-jena.github.io


For ROI analysis, however, you have to use your old fancy equations...

Best, Christian

On Sun, 1 Dec 2024 10:19:48 +0000, Domes, Gregor <domes@UNI-TRIER.DE> wrote:

>Dear CAT12 experts, dear Christian,
>
>I have another question regarding effect sizes. From time to time there is the question of how 
effect sizes can be calculated for the voxel-based analyses and for the ROI analyses. I would like 
to calculate effect sizes for both approaches for comparison. Is this possible in CAT12? Or is an 
export necessary? I am grateful for any advice!
>
>Thank you,
>Gregor
>
>

Dear all

The Department of Imaging Neuroscience at UCL is hiring! We’re seeking an exceptional researcher to 
lead a programme in Cognition & Perception and shape the future of the new BSc in Human 
Neuroscience. Join us at the cutting edge of neuroscience! 🔬🧠


For full details and to apply, please visit our website. The closing date is 2nd January 2025.

 

Best

Peter

 

Professor Peter Zeidman

Group Leader, Neurovascular Modelling Group

Chair, Methods Group

Functional Imaging Laboratory (FIL)

UCL Queen Square Institute of Neurology

12 Queen Square, London, UK. WC1N 3AR

 

I would greatly appreciate it if you could forward this job announcement to mailing list.

1 Doctoral Position in Cognitive Neuroscience, Freiburg (The Imaging Memory and Consolidation Lab 
(ImaC Lab)
The BAWÜ Stiftung funded project seeks an applicant for one Doctoral Position (E 13 TVöD %75; 39 
hours/week).
The position is available from April 1st, 2024.
We are looking for a candidate who will investigate effect of sleep disruption on memory 
reprocessing in younger and older adults using concurrent recordings of fMRI and EEG.

The position is for 3 years.
Requirements for PhD applicants:
- MSc in mathematics, physics, neuroscience, psychology, natural sciences, engineering, or a 
related area, by the agreed start date of the position
- experience with one of these three areas: (a) EEG, (b) fMRI, (c) decoding or multivariate 
approaches
- experience with Matlab (SPM, fieldtrip) and R
- Excellent English skills
- Excellent organizational, communication and social skills, independence, reliability
- A strong research interest in memory and sleep will be highly beneficial. Applicants should 
submit a current CV, a personal statement describing their experience and interests, and contact 
information for two referees, as a single PDF document, by 06 January 2025 to 
deniz.kumral@psychologie.uni-freiburg.de.  Enquiries can be directed to Dr. Deniz Kumral.

Dear CAT12 experts, dear Christian,

 

I have another question regarding effect sizes. From time to time there is the question of how 
effect sizes can be calculated for the voxel-based analyses and for the ROI analyses. I would like 
to calculate effect sizes for both approaches for comparison. Is this possible in CAT12? Or is an 
export necessary? I am grateful for any advice!

 

Thank you,

Gregor

Dear CAT12 experts!

 

I have some questions:

 

a) In a simple group comparison, I analyzed regional volumes using VBM and cortical thickness using 
SBM (n=20 vs. n=20). The effects are an order of magnitude stronger in the VBM analyses (many 
cluster with p<.05 corr.), but are also partly found with regard to cortical thickness in some 
cortical regions (p<.001 uncorr.). I wonder whether this could simply be an effect of different 
(statistical) sensitivity of the two procedures, or rather means that less strong effects were 
observed with regard to cortical thickness because there were simply no differences here. Is it 
conceivable that the volume of gray matter in the cortex is reduced without a decrease in cortical 
thickness?

 

b) The effects of the VBM ROI analysis appear even stronger than those of the voxel-wise analysis. 
I assume that the ROI analysis is simply more sensitive, right?

 

c) In the voxel-wise VBM, I included the TIV as a covariate because there are differences between 
the groups. I understood the explanations in the manual to mean that all covariates are then also 
taken into account in the ROI analysis. Is that correct? But the exported ROI volumes are raw 
values and not the residuals, or have I misunderstood something?

 

Maybe some of you have similar questions or even answers...

 

Many thanks and best regards!

Gregor

The Department of Cognitive Psychology, located at Universität Hamburg, is inviting students of 
exceptional talent to apply for a 3 years PhD position (E13, 75%; extension possible) at the 
intersection of Psychology and Cognitive Neuroscience. The starting date is April 2025.

We offer:       
- a strong and highly visible international research environment, including excellent access to 
cutting-edge research facilities
- exceptional support, mentoring and career development
- access to an interdisciplinary and structured research training group (emotionalmemory.de)

The successful candidate will work on an exciting project directed at understanding the neural and 
cognitive processes that underlie the impact of emotion and stress on learning, memory, and 
decision-making.

For more details on our research, please see:
https://www.psy.uni-hamburg.de/en/arbeitsbereiche/kognitionspsychologie.html

We are inviting highly qualified students holding a MSc. or equivalent in Psychology, Medicine, 
Neuroscience or a related discipline who share our enthusiasm for interdisciplinary research. We 
expect excellent methodological skills, programming skills (e.g. MATLAB, Phython, R) and 
statistical knowledge as well as the openness to learn new techniques.

To apply, please send your CV, a letter of motivation, contact details of two references as well as 
copies of all relevant certificates – by January 6th, 2025 – via the application platform of the 
University of Hamburg:

https://www.uni-hamburg.de/stellenangebote/ausschreibung.html?jobID=a114523e0e71b0d3134270b91a9fb6c5f97cbd42
 
(Please use the “apply” button at the bottom of the application page)

The [www.caian.uni-bonn.de/en/]Hertz Chair for Artificial Intelligence and Neuroscience at 
University of Bonn is looking to recruit a postdoctoral fellow or PhD student to undertake high 
quality research and produce high-impact publications in a collaborative research project 
investigating human escape using wearable magnetoencephalography with optically pumped magnometers 
(OPM).

The goal of the advertised position is to understand the neural control of human escape decisions 
in an immersive virtual reality (VR) environment using an OPM-compatible HMD, in collaboration with 
the Wellcome Platform for Naturalistic Neuroimaging, which is part of the FIL at the UCL Queen 
Square Institute of Neurology, London, UK. The role includes

- conceptual design of naturalistic VR scenarios that allow MEG recordings
- planning, conducting, and analysing MEG experiments
- building robust pipelines for MEG analysis in naturalistic settings
- publication of research and development results

See here for an example of our previous behavioural research in virtual reality.

Requirements for post doc applicants:
- PhD in neuroscience, cognitive psychology, behavioural science or a related area, by the agreed 
start date of the position (essential)
- experience with (cryogenic or wearable) MEG (essential)
- experience with Matlab (SPM or fieldtrip) and R (tidyverse) (essential)
- experience with virtual reality (preferably Unity and C#) would be a plus
- experience with analysing movement data would be a plus

Requirements for PhD applicants:
- MSc in neuroscience, psychology, natural sciences, engineering, or a related area, by the agreed 
start date of the position (essential)
- experience with one of these three areas: (a) MEG (cryogenic or wearable), (b) EEG, (c) virtual 
reality (preferably Unity and C#)
- experience with Matlab (SPM or fieldtrip) and R (tidyverse) (essential)
- experience with analysing movement data would be a plus

The successful candidates on either level will have ample experience in programming, and a good 
publication record.

Applicants should submit a current CV, a personal statement describing their experience and 
interests, and contact information for three referees,  as a single PDF document, by 15 January 
2025 to caian.office@uni-bonn.de. Interviews will be conducted online between 27 January and 7 
February 2025. Enquiries can be directed to Prof. Dominik Bach, d.bach@uni-bonn.de.

More information can be found here.

-- 
-----------------------
Prof. Dominik R Bach, MBBS PhD
Hertz Chair for Artificial Intelligence and Neuroscience 
University of Bonn
Am Propsthof 49
53121 Bonn, Germany
https://www.caian.uni-bonn.de/en/ | @bachlab_cog

Hello!

I'm working through the MEG source localisation tutorial as described here: 
https://www.fil.ion.ucl.ac.uk/spm/docs/tutorials/MEEG/meg_sloc/, using the data linked in the 
tutorial (Preprocessed MEG data (SPM12 format): cdbespm12_SPM_CTF_MEG_example_faces1_3D.zip).

While following the tutorial instructions for simulating data using the "Simulation of sources" 
module, I receive an error message indicating that the forward model is missing. Specifically, 
after setting up the simulation parameters as per the tutorial, when I click the Run button in the 
batch editor, I get the following error:

"Error using spm_cfg_eeg_inv_simulate>run_simulation (line 213)
Forward model is missing for subject 1
In file "/Users/inga/Downloads/spm12/config/spm_cfg_eeg_inv_simulate.m" (v6926), function 
"run_simulation" at line 213.

The following modules did not run:
Failed: Simulation of sources"

Is the forward model supposed to be precomputed in the provided sample dataset for this tutorial? 
The tutorial does not mention computing the forward model as a prerequisite for this step, so I am 
unsure if this is an oversight or if I have missed a step.

I would appreciate any help in resolving this issue. As I'm new to SPM, it's possible that I might 
be making an error due to my inexperience with the software, but I'd like to double-check this all 
the same.

All the best,

Inga Almklov

To be more specific, I was trying to extract mean activations using contrast files created in SPM. 
My ROI mask is binarized. I did not scale the data (i.e., raw extracts), and the differences that I 
saw between the two analyses were in the `Y` field of `regions`.

To my understanding the dimensions of `regions.Y`, in my case, would represent Nsubjects X Nvoxels. 
When analyzing a subset of my subjects, not only does Nsubjects differ, but also Nvoxels does. In 
addition, certain columns in the `regions.Y` matrix that exist when extracting for a subset of the 
subjects do not exist when extracting for all the subjects.

My reading implies that this is because Marsbar only extracts from voxels that have "valid" data 
across ALL subjects -- thus the more subjects I include, the more "invalid" voxels may be 
introduced, decreasing the value of Nvoxels in `regions.Y`.

If this is accurate (which I am not sure about...), then I am wondering what I can do to preserve 
as much data as possible. The volume of my ROI mask is >1000 voxels, but the Nvoxel value when I 
extract activations from all of my subjects is only ~450. Is there a way to make Marsbar not 
exclude voxels that are "invalid" as a whole, and maybe instead give them an NA or 0 value so that 
data is not lost from subjects who have "valid" voxels that may not be "valid" for other subjects? 
Or is this amount of data being lost considered normal in the field?

Any help or guidance towards resources would be greatly appreciated.

Thank you,
Ha Jeong

Dear SPM-Users,

I am part of the organizing committee of ESMRMB's MRITogether24 (December 3rd to December 6th,  
2024), and our focus this year is on "Staying Together", i.e., how to make open MRI efforts 
sustainable and long-lasting. As SPM is one of the pioneers of open software in the MRI domain (and 
beyond), we thought this conference may be of interest to many here.

The deadline for abstract submission is coming up (Wed, Nov 27th), and there are poster cash prizes 
up to EUR 150 available, so we would be thrilled if you could encourage your students to submit 
their work in this domain and register for this free, online-only event. We would also be very 
grateful if you could circulate this information among your colleagues around the world.


MRITogether24 is a free virtual global workshop on open, reproducible, and inclusive MR, supported 
by the European Society for Magnetic Resonance in Medicine and Biology (ESMRMB). It is organised 
for the fourth time since 2021 and will span multiple time zones between December 3rd to December 
6th,  2024. Last year, we achieved over 800 registrants from around the world.

Looking forward to seeing you there!

All the best,
Lars
on behalf of the MRITogether24 organizing committee


-- 
Lars Kasper, PhD (he/him)
Lars.Kasper@utoronto.ca

MR Physicist
Toronto Neuroimaging Facility (ToNI), Department of Psychology, University of Toronto

Dear CVnet community, 

Kindly find a job ad for a post-doc position at EPFL on Computational Visual Neuroscience below. 

Best wishes,
   Dimitri

—

Post-Doctoral Researcher at EPFL on Computational Visual Neuroscience – start date ASAP

Position Description

We are seeking a postdoctoral researcher for a one-year (renewable) project within the MIP:Lab of 
the Ecole Polytechnique Fédérale de Lausanne (EPFL) located at the Campus Biotech in Geneva, 
Switzerland. The project is at the interface between an industrial partner (Dandelion Science) and 
the MIP:Lab headed by Prof. Dimitri Van De Ville.

Start date is as soon as possible (date may be negotiable) and will last for approximately 15 
months. At the end of the postdoc, there will be an opportunity to join the company as an employee.

The post-doctoral researcher will join a team of academic and industrial group members to work on 
new computational modeling frameworks for rapidly time-varying functional networks in late sensory 
and non-sensory cortex in the context of biofeedback-influenced video viewing. A mix of 
theoretical, algorithmic, and empirical work is expected, in collaboration with an industrial 
partner in the healthcare technology/AI field providing behavioral and neural (streaming M/EEG) 
data. Some first-hand behavioral and neural data (M/EEG) is also expected to be acquired in the 
M/EEG Platform at the Campus Biotech.

We are interested in maintaining the rich diversity in our work teams and encourage applications 
from all interested candidates. The salary range at EPFL is competitive and the quality of living 
in Switzerland is outstanding.

Qualifications

The ideal candidate will have a PhD, strong quantitative, signal processing, and machine learning 
skills, data analytic expertise (Python and Matlab), and enthusiasm for broadly advancing the 
treatment of neurological disorders. Experience with neuroimaging is required, preferably with 
human subjects. The candidate should be creative, enjoy problem solving, and be prepared to 
collaborate within a larger team with diverse expertise. Experience in commercial biomedical 
development is also preferred. Appropriate background/training includes systems or engineering, 
physics, machine learning and data science, as well as cognitive neuroscience.

Application Instructions

Please send your motivation letter, CV with publication list, one-page personal research statement, 
and contact information of three referees, to with subject line “[CV-POSTDOC] <Your Name>” to 
dimitri.vandeville@epfl.ch 

Job Type: 100%
Work Location: In person


— 
Dimitri Van De Ville
Professor, Fellow IEEE & EURASIP
Neuro-X Institute
EPFL - Ecole Polytechnique Fédérale de Lausanne

Professor, Department of Radiology and Medical Informatics
University of Geneva

Switzerland
URL: http://miplab.epfl.ch/
Twitter: @dvdevill

The Functional Neuroscience and Pathology Laboratory (UR-UPJV 4559, Amiens, France) is looking for 
a motivated candidate to respond to a call for postdoctoral funding (AAP MOPGA, Campus France, 
deadline 4 December). 

For several years, various research projects have explored the interactions between emotions and 
motor skills by recording postural correlates during the processing of emotional stimuli. We 
recently decided to apply this methodology to the perception of visual pollution (Beaumont et al., 
2020; Akounach et al., 2022). Our results show the relevance of posturography for studying motor 
reactions linked to the perception of pollution, and the central role of emotions and the subject's 
immersion in the appreciation of landscapes and pollution. A major limitation of this work is the 
lack of information on the neural processes involved in these motor changes. In this work, we 
wanted to use functional neuroimaging methods such as EEG and/or NIRS to jointly collect postural 
and neural responses during the perception of environmental scenes and the associated disturbances 
caused by visual pollution.

Applicants must :

• be of foreign nationality

• have obtained a doctorate (neuroscience, psychology, etc.) within the last 5 years (thesis 
defended between December 2019 and December 2024)

• not have been resident in France for more than 90 days between 5 September 2024 and 5 December 
2024

• having the following interests/skills: affective neuroscience, EEG analyses, appetence for motor 
responses recording techniques.

• send the following documents to [harold.mouras@u-picardie.fr] before 30/11/2024 (submission of 
the successful candidate's file on 04/12/2024):

– CV including list of publications in English (4 pages maximum)

– thesis diploma

– letters of recommendation (maximum 3)

– subsequently, if successful, proof of identity

Professeur de Neurosciences 
Laboratoire de Neurosciences Fonctionnelles et Pathologies (LNFP) EA 4559 
CHU Amiens Picardie - Site Sud 
Centre Universitaire de Recherche en Santé (Bâtiment CURS) 
Avenue René Laënnec 
80054 Amiens Cedex 1 
Tél: (+33) (0)7 83 62 93 31 
E-mail: harold.mouras@u-picardie.fr



Hi all,

I'm using MarsBaR to extract ROI activation data and am finding that I get slightly different 
values when extracting data from a subset of the subjects I am analyzing, even after 
double-checking that I use the same exact procedure for both the full set of subjects and the 
subset.

For example, if Set A includes subjects 1 to 100, and Set B includes subjects 1 to 10 (i.e., a 
subset of Set A), the activations for subjects 1 to 10, which should stay the same, have slightly 
different numbers.

I compared the *_mdata.mat files from both analyses to see where the difference comes from, and it 
seems that the `regions` structure is what differs, both in size and values. I'm having trouble 
with finding out what this structure means, and why this structure would be different for my two 
analyses, where the only difference would be whether there are any additional subjects or not.

So my questions would be...

1. Why am I getting different values?
2. The `regions` structure in *_mdata.mat seem to be different -- what does this mean, and would 
this be causing the difference in values? Is this supposed to happen?

Any help or directions to resources would be appreciated.
Please let me know if more clarification is needed.
Thank you!

Best,
Ha Jeong

Dear Torsten

Happy to clarify. The SPM Dev version is the current codebase on Github 
(https://github.com/spm/spm) . It has all the latest features, but does not have the same level of 
testing as an official release.

 

The next release, SPM 25.01, will be in January 2025. You can already access the pre-release 
version, which is made available for testing purposes - 
https://github.com/spm/spm/releases/tag/25.01.rc3 .

 

The previous version of SPM, SPM12, lacks a lot of features related to DCM, as well as advanced 
pre-processing that you may want to use with VBM (i.e., SHOOT toolbox).

 

So my recommendation would be to use 25.01.rc3 now and switch to 25.01 in January (although, don’t 
mix SPM versions for one analysis, in case that reduces reproducibility).

 

Best

Peter

 

From: SPM (Statistical Parametric Mapping) <SPM@JISCMAIL.AC.UK> On Behalf Of Torsten Klenert
Sent: 19 November 2024 17:01
To: SPM@JISCMAIL.AC.UK
Subject: {SPAM?} [SPM] SPM actual development version

 

⚠ Caution: External sender

 

Hello to all people who are using SPM,

 

I have a question about the actual SPM software. I have subscribed new to the email discussion list 
because this is my first time I'm using SPM for a fMRT-analysis.

As I have learned from the last fMRT Workshop that it was recommended to use the development 
version of the SPM "spm-dev-5ed514d.zip".

The departement which I'm actually working does not actually use the development version of the SPM 
which is not a problem because I have the opportunity to use the SPM on a single desktop PC.

Is there anything a have to mind when I'm using the development version? I wanna make sure that I 
will not have some issues which the development version of the SPM for a fMRT analysis. From the 
view as a scientist what version would you recommend for my research question if I'm using:

 

Dynamic Causal Modelling (DCM) for task fMRI (e.g. group-level DCM analysis)
Advanced Voxel Based Morphometry (VBM)
Dynamic Causal Modelling (DCM) for resting-state fMRI
 

Is it better to use the development version? I would appreciate to get any answer to make it a 
little bit clear for a beginner of using the actual SPM software (of course I want to use the best 
actual software which is possible).

 

Best regards from Germany,

Torsten Klenert

 

RPTU Landau and university hospital Tübingen

M. Sc. Clinical psychology and neuroscience

 

 



On Mac you can go to your system security settings in ?utilities. There it will tell you the last 
file blocked, and there is an option to allow the system to accept and run. You need to repeat this 
process 4 or 5 times (per mex file that upsets it, bit tedious but I’ve not found a quicker way). 
In my experience, once you have done that, it should all be fine (until Mac decides to change 
everything again at least).

Hope that helps - can send some screen caps if any trouble navigating the above 👆

Chris

> On 19 Nov 2024, at 11:29, Subscribe Spm Ge Qiu <0000f41cc1b3e5ea-dmarc-request@jiscmail.ac.uk> 
wrote:
>
> ﻿Dear Amir,
> Thank you for your response regarding my issue. I have already downloaded and am using the latest 
development version of SPM12 from the GitHub repository. However, the problems persist.
>
> Here are the key details and steps I’ve followed:
>
> MEX File Compilation:
> I navigated to the src directory and ran make &&amp; make install. While most MEX files compiled 
successfully, spm_jsonread.c failed with unresolved symbols related to jsmn:
> Undefined symbols for architecture arm64:
>  "_jsmn_init", referenced from:
>      _mexFunction in spm_jsonread.o
>  "_jsmn_parse", referenced from:
>      _mexFunction in spm_jsonread.o
> MacOS Security Restrictions:
> I attempted to allow .mexmaca64 files using spctl: sudo find ./ -name "*.mexmaca64" -exec spctl 
--add {} \;
> This failed with the message:
> This operation is no longer supported. Please see the man page for more info
>
>
> Thank you again for your support. I look forward to your advice.

Hi everyone

Last chance to sign up for our 2-day seminar Introduction to Web App Development with R Shiny, 
running Nov 20 - 21. This workshop provides an extensive introduction to developing interactive web 
applications using R Shiny, enabling participants to create, deploy, and optimize data-driven web 
tools. Ideal for PhD students, academics, and professional researchers, the course covers 
fundamental and advanced concepts tailored to enhance research presentation and real-time 
analytical communication across various scientific domains. From big to small data cases, the 
ability to build and deploy web applications using R Shiny will significantly improve participants 
ability to convincingly communicate their research findings to a broad audience -- including 
journal and grant reviewers.

Sign up today to secure your spot in this unique event, and please feel free to tell your 
colleagues and students.


Best wishes

Michael Zyphur
Director
Institute for Statistical and Data Science
instats.org

Dear Christine (CC’d mailing list)

Sorry for the delay in replying.

 

Just to let you know the bug in the DCM group specification batch should now be fixed - thanks 
again for reporting it 
(https://github.com/spm/spm/commit/c7bd1f301b249c912dbaa299b53e693f57a70af9).

 

1. I have been trying to determine how to create a good model. My goal is first to identify a model 
that explains my data well in healthy participants. In a second step, I want to apply this model to 
patients and see which parameters change. To approach model selection systematically, I used the 
following procedure:

   - I created a fully connected model and applied it to a group of 23 homogeneous healthy 
participants. From this, I specified and estimated a group model across all participants and then 
performed a PEB analysis without covariates.

   - I then examined the individual parameters of my model, focusing on those that remained above a 
threshold of 0.95, considering these as important for my model, and used them to form a new reduced 
model.

My question here would be whether this is a valid approach?

 

Yes, that is a valid approach. Note that these are not guaranteed to be the connections that best 
explain the *difference* between groups. For that you would need to create one PEB model with all 
your subjects (patients and control) with a covariate indicating group.

 

2. The participants had two sessions each. Initially, I applied this procedure only to the first 
session. I then applied the same approach to the second session to see if I could find the same 
stable parameters above the 0.95 threshold. However, the results for the A and B matrices differ 
significantly between the two sessions. I'm not sure how to proceed with this discrepancy.

Would you have any suggestions on how I should handle this?

 

My preferred approach is to concatenate the two sessions at the stage of creating the onsets and 
specifying the first level GLMs. Then the DCM analysis will be simpler, because you will only have 
one ROI timeseries per subject (per region), and then one DCM per subject. Instructions for doing 
this can be found at https://en.wikibooks.org/wiki/SPM/Concatenation .

 

3. I currently have a total of 6 VOIs. To generate these for all subjects, I used the Batch Editor 
for one participant and then adapted the script to add more subjects (Batch Editor - Util - Volume 
of Interest). When generating the VOIs, I select "Effects of interest" under "adjust data," as 
indicated on the SPM homepage. In the "old" SPM12, I enter "NaN" to adjust for all conditions. In 
the Development Version of SPM, as I understand from the Batch Editor, I need to enter "eye(2)" 
since I have two conditions. However, no matter what I enter, the Development Version does not 
accept anything in this field. Therefore, I have continued to use SPM12 to generate the VOIs.

 

This behaviour hasn’t changed across SPM versions, to the best of my knowledge. Entering “NaN” will 
treat everything in your design matrix as uninteresting and regress everything out. It is intended 
for resting state analysis, not task fMRI. You were correct to enter eye(2), if the first two 
columns in your design matrix were the only interesting ones. To be clear, you need to create an 
F-contrast for each subject with matrix eye(2). Then during timeseries extraction, you need to 
specify the *index* of that contrast. E.g. enter 1 if the F-contrast was the first contrast, or 10 
if it was the tenth contrast. I recommend always putting the effects of interest F-contrast first, 
so that the index is 1.

 

If it’s still not accepting that, then it is most likely that there is an issue with the design 
matrix (formally it’s not what SPM defines as a “valid contrast”). If so, please could you paste 
into an email a screenshot of your design matrix?

 

4. Next, I specify the DCM models for each participant. We assume that condition 1 (Task) has an 
influence on the network, while condition 2 (Baseline) does not. My specifications for the fully 
connected model are as follows:

 

   ```

   nu = 2; % Number of conditions

   % A-Matrix

   a = ones(nRegions, nRegions); % All regions are connected with each other

 

   % B-Matrix

   b = zeros(nRegions, nRegions, nu); % Initialization of modulatory connectivity

   b(:, :, 1) = 1; % Condition 1 affects all connections

   b(:, :, 2) = 0; % Condition 2 does not affect any connections

 

   % C-Matrix

   c = zeros(nRegions, nu); % Initialization of the C-Matrix

   c(:, 1) = 1; % Condition 1 affects all regions

   c(:, 2) = 0; % Condition 2 does not affect any region

 

   % D-Matrix

   d = zeros(nRegions, nRegions, 0); % No non-linear effects

   ```

 

When I run the script for the model, I do not get an error message, but I do receive a warning each 
time:

 

   ```

   > In spm_dcm_specify_ui (line 248)

   > In spm_dcm_specify (line 139)

   > In g_DCM_model_1 (line 74)

   Warning: VOIs were adjusted using different F-contrasts. This may not have been intentional.

   > In spm_dcm_specify_ui (line 106)

   > In spm_dcm_specify (line 139)

   > In g_DCM_model_1 (line 74)

   Warning: Condition AM was excluded using an effects of interest F-contrast during VOI 
extraction, but was included in the DCM. Please revisit VOI extraction.

   ```

 

As I understand it, I can simply ignore this warning, or am I mistaken?

 

No you should not ignore this warning. It means that different contrasts were used to adjust the 
different timeseries. Please see above.

 

5. In general, I’m wondering if, when specifying a model for a participant in the GUI, there is any 
difference if I answer “yes” to the question “include cond 2?” and then specify that it has no 
influence on any matrix versus simply answering “no” to the question?

 

I don’t think there’d be any difference. However, it’s important you tell DCM about all your 
conditions, as that’s the only way it can deconvolve (unmix) overlapping BOLD responses. So 
consider putting cond 2 and any other uninteresting conditions as driving inputs, and just have 
your interesting condition(s) as modulatory inputs.

 

6. Additionally, in my model I specify the delays as `s.delays = repmat(TR/2, 1, nRegions);`, which 
defaults to ½ TR. Does this make sense in my case? Our TR is quite long at 3.4 seconds...

 

Yes, leave this on TR/2 for each region.

 

7. In all my testing, I also once had 14 models with 13 VOIs distributed across both hemispheres 
for 23 participants. Here, I finally tried to estimate the models and create a group model. 
However, I got the following error message at the very end:

 

   ```

   EM:(-): 10     F: 3.354e+00 dF predicted: 4.498e-03  actual: -9.092e-03 (34.99 sec)

   EM:(-): 11     F: 3.354e+00 dF predicted: 6.113e-04  actual: -1.714e-03 (34.45 sec)

   EM:(-): 12     F: 3.354e+00 dF predicted: 8.278e-05  convergence

 

   Please ensure your models are nested

   10-Nov-2024 14:46:57 - Failed  'DCM estimation'

   Output argument "RCM" (and possibly others) not assigned a value in the execution of the 
"spm_dcm_bmr" function.

   In file "/Applications/spm/spm_dcm_bmr.m", function "spm_dcm_bmr" at line 68.

   In file "/Applications/spm/config/spm_cfg_dcm_est.m", function "spm_run_dcm_est" at line 366.

 

   The following modules did not run:

   Failed: DCM estimation

   ```

 

   I couldn't find anything about this error online. To troubleshoot, I have reduced the script and 
run it multiple times:

 

   - With all 23 subjects and model 1, plus 4-5 "nested" models. Regardless of which models were 
included, everything ran without issues.

   - With all models but only five subjects—also without any issues.

   - However, whenever I included six subjects, the error occurred.

   - I have also never encountered this error when using fewer VOIs in my models.

 

   Could it be that the number of VOIs or the number of included models is too large for the number 
of subjects? Or could it be an issue with memory or available resources? I am working on a Mac with 
32GB of RAM, an Apple silicon processor (Apple M2 Pro), and I am using MATLAB 2023b for Intel Macs.

 

If you specify multiple DCMs per subject, and for the estimation option in batch you select “Full + 
BMR (default)”, then it assumes that the first DCM is a “full” model with all interesting 
connections switched on, and the other models are “reduced models” with certain mixtures of 
connections switched off. For each subject, it first estimates the full model, then it uses an 
analytic procedure to work out the free energy and parameters of the reduced models. You received 
the error because there were connections switched on in the reduced models that were not switched 
on in the full model.

 

However, I suggest you take a different approach, which we generally recommend:

Just estimate one “full” model for every subject. This should have all parameters of interest 
switched on.
Specify a second level (between-subjects) PEB model. This is a linear regression model fitted to 
all subjects’ connectivity parameters. The PEB model will have one regression parameter per 
covariate per connection.
Compare the evidence for this full PEB model against reduced PEB models where particular mixtures 
of effects are switched off (e.g. all regression parameters relating to a particular connection). 
To tell PEB which connections to switch on or off, you can use the other 13 models you created 
earlier as templates.
 

You can either perform this procedure using the batch, or using scripting for greater control. For 
details on how to script this, please see our old Wiki: 
https://en.wikibooks.org/wiki/SPM/Parametric_Empirical_Bayes_(PEB) .

 

I hope that helps,

Peter

 

 

-----Ursprüngliche Nachricht-----

Von: Zeidman, Peter <peter.zeidman@ucl.ac.uk>

Gesendet: Montag, 28. Oktober 2024 09:23

An: Kindler, Dr. Christine <Christine.Kindler@ukbonn.de>; SPM@JISCMAIL.AC.UK

Betreff: RE: [SPM] DCM Group Analysis

 

Dear Christine

Thank you for getting in touch. My initial guess is that the "Specify Group" batch expects all the 
subjects to have the same number of fMRI volumes, which is not a good assumption and is not the 
case here.

 

I aim to confirm whether this is indeed the issue and create a fix to SPM this week.

 

In the meantime, if you need a faster resolution and you are happy with scripting, you could write 
a script to generate all your subjects' DCM, rather than using the batch. I paste some example code 
below, from the help text at the top of spm_dcm_specify.m .  This requires the SPM Dev version from 
Github. You would put this code in a for loop to generate DCMs for each subject.

 

Best

Peter

 

Example for a task-based experiment:

-------------------------------------------------------------------------

n   = 3;    % number of regions

nu  = 2;    % number of inputs (experimental conditions)

TR  = 2;    % volume repetition time (seconds)

TE  = 0.03; % echo time (seconds)

 

% Experimental conditions to include from the SPM.

% To see the conditions' names, load your SPM.mat into the workspace and % inspect 
SPM.Sess(s).U.name, where s is the session (run) number.

cond = struct();

cond(1).name    = 'Condition1'; % desired name for the condition

cond(1).spmname = {'c1','c2'};  % (optional) corresponding name(s) of

                                % conditions in the SPM.mat file, see

                                % SPM.Sess(s).U.name. If multiple names

                                % are provided then they will be combined

                                % by binarizing the regressors and performing

                                an 'OR' operation.

 

cond(2).name    = 'Condition2';

cond(2).spmname = {'c3','c4'};

 

% Connectivity matrices

a  = ones(n,n);

b  = zeros(n,n,nu);

c  = ones(n,nu);

d  = zeros(n,n,0);

 

s = struct();

s.name       = 'test';

s.cond       = cond;

s.delays     = repmat(TR/2, 1, n);

s.TE         = TE;

s.nonlinear  = false;

s.two_state  = false;

s.stochastic = false;

s.centre     = true;

s.induced    = 0;

s.a          = a;

s.b          = b;

s.c          = c;

s.d          = d;

DCM = spm_dcm_specify(SPM,xY,s);

 

 

Tips:

- You can either select which experimental conditions to include by using the s.cond structure, as 
illustrated above, or by specifying a matrix s.u(i,j), which sets whether to include regressor j of 
condition i from the SPM design matrix. If there are no parametric regressors, then j will always 
equal one.

 

- xY is a cell array of strings containing the filenames of the VOIs to include.

 

-----Original Message-----

From: SPM (Statistical Parametric Mapping) <SPM@JISCMAIL.AC.UK> On Behalf Of Christine Kindler

Sent: 24 October 2024 09:40

To: SPM@JISCMAIL.AC.UK

Subject: [SPM] DCM Group Analysis

 

⚠ Caution: External sender

 

 

Dear SPM experts,

 

I am reaching out because I have encountered an issue with my DCM group analysis and I am unsure 
how to proceed.

 

Briefly about the design of the analysis: For each subject, I specified and estimated a GLM on a 
single-subject level with one session, two contrasts, six motion parameters as regressors, and a TR 
of 3.4 seconds – all without issues. From this, I generated a total of 8 VOIs. Subsequently, I 
specified and estimated three different DCM-models for one of the subjects at the individual level– 
again, without any issues. Now, I would like to run a group analysis via the Batch Editor → DCM → 
DCM specification → DCM for fMRI → specify group to determine which of my three models best 
explains the data. For "Full DCM," I entered the first fully connected model of the single subject, 
and for "Alternative DCMs," the other two models that were also generated for this individual 
subject. For "SPM.mat files," I included the GLM.mat files of all the subjects, and for "Regions of 
Interest," I specified each VOI of each of the subjects.

 

When I try to run the batch, I get the following error message:

"Input period and output period do not match. Number of inputs=2912, input dt=0.21, input 
period=618.80. Number of outputs=196, output dt=3.40, output period=666.40."

 

In the DCM specification for individual participants, a `DCM.U.dt` of 0.2125 seconds is used. My 
understanding is that the total input duration (618.80 seconds) does not match the total duration 
of the BOLD time series (666.40 seconds).

 

I suspect that the issue might be related to the temporal resolution of the input data (U), which 
could be due to the GLM design or the specification of the stimulus onsets. I have checked 
`DCM.U.dt` for all models, and it seems to be consistently 0.2125 seconds across all models, but it 
evidently does not match the TR of the BOLD data.

 

Could you help me understand where the value of 0.2125 seconds for `DCM.U.dt` comes from and how I 
could resolve this issue so that the inputs and outputs are better aligned?

 

Thank you very much for your help.

 

Best wishes,

Christine

 

________________________________

 

Vorstand: Univ.-Prof. Dr. Bernd Weber – komm. Vorstandsvorsitzender und Dekan der Med. Fakultät • 
Clemens Platzköster – Kaufmännischer Direktor und stellv. Vorstandsvorsitzender • Univ.-Prof. Dr. 
Alexandra Philipsen – komm. Ärztliche Direktorin • Univ.-Prof. Dr. Johannes Oldenburg – komm. 
stellv. Ärztlicher Direktor • Alexander Pröbstl – Vorstand Pflege und Patientenservice • 
Aufsichtsratsvorsitzender: Univ.-Prof. Dr. Heinz Reichmann Anstalt öffentlichen Rechts • 
Gerichtsstand Bonn • Finanzamt Bonn Innenstadt • Ust-IdNr.: DE 811 917 555 • Bank: Sparkasse 
KölnBonn • BIC COLSDE33 • IBAN DE52 3705 0198 0010 6506 61

Dear Amir,
Thank you for your response regarding my issue. I have already downloaded and am using the latest 
development version of SPM12 from the GitHub repository. However, the problems persist.

Here are the key details and steps I’ve followed:

MEX File Compilation:
I navigated to the src directory and ran make &&amp; make install. While most MEX files compiled 
successfully, spm_jsonread.c failed with unresolved symbols related to jsmn:
Undefined symbols for architecture arm64:
  "_jsmn_init", referenced from:
      _mexFunction in spm_jsonread.o
  "_jsmn_parse", referenced from:
      _mexFunction in spm_jsonread.o
MacOS Security Restrictions:
I attempted to allow .mexmaca64 files using spctl: sudo find ./ -name "*.mexmaca64" -exec spctl 
--add {} \;
This failed with the message:
This operation is no longer supported. Please see the man page for more info


Thank you again for your support. I look forward to your advice.

I think you would have to use the developer's version of SPM12 (can be downloaded from the GitHub 
repo).

Amir Dehsarvi
Postdoctoral Researcher

LMU Hospital
Institute for Stroke and Dementia Research (ISD)

Campus Großhadern | Feodor-Lynen-Straße 17 | 81377 Munich
phone +49 (0)89 4400-46157

amir.dehsarvi @med.uni-muenchen.de <mailto:anton@med.uni-muenchen.de>
www.isd-research.de <http://www.isd-research.de/>
www.lmu-klinikum.de/isd <https://www.lmu-klinikum.de/isd>



﻿On 19.11.24, 10:13, "SPM (Statistical Parametric Mapping) on behalf of Subscribe Spm Ge Qiu" 
<SPM@JISCMAIL.AC.UK <mailto:SPM@JISCMAIL.AC.UK> on behalf of 
0000f41cc1b3e5ea-dmarc-request@JISCMAIL.AC.UK 
<mailto:0000f41cc1b3e5ea-dmarc-request@JISCMAIL.AC.UK>> wrote:


I am using the development version of SPM12 on macOS Ventura (Apple Silicon, M4) with MATLAB 
R2023b. I encountered issues when trying to compile and run MEX files. Here are the key problems:


Attempting to allow .mexmaca64 files using spctl （sudo find ./ -name "*.mexmaca64" -exec spctl 
--add {} \;）results in:
this operation is no longer supported. Please see the man page for more information.


Some MEX files seem to be blocked by macOS security policies and cannot be executed.


I would appreciate any guidance on:


Is there an updated guide or recommended steps for running SPM12 or
alternative methods to enable trust for .mexmaca64 files in macOS Sequoia15.1.




I would greatly appreciate any guidance or recommendations to resolve these issues.


best regards
GeQiu




I am using the development version of SPM12 on macOS Ventura (Apple Silicon, M4) with MATLAB 
R2023b. I encountered issues when trying to compile and run MEX files. Here are the key problems:

Attempting to allow .mexmaca64 files using spctl （sudo find ./ -name "*.mexmaca64" -exec spctl 
--add {} \;）results in:
this operation is no longer supported. Please see the man page for more information.

Some MEX files seem to be blocked by macOS security policies and cannot be executed.

I would appreciate any guidance on:

Is there an updated guide or recommended steps for running SPM12 or
alternative methods to enable trust for .mexmaca64 files in macOS Sequoia15.1.


I would greatly appreciate any guidance or recommendations to resolve these issues.

best regards
GeQiu

Dear SPM Experts,

I am currently using SPM12 on macOS Ventura (Apple Silicon, M4, Sequoia15.1), with MATLAB R2023b, 
and I encountered issues compiling spm. I am using the development version of SPM12, downloaded 
from the github. I have encountered several issues related to compiling and running MEX files. Here 
are the details of my situation:
I tried with this：Grant permission for SPM compiled files. In MATLAB, run the following commands 
one by one:
cd(fileparts(which('spm.m')))
!sudo xattr -r -d com.apple.quarantine ./

Attempted to address macOS security restrictions by running:
sudo find ./ -name "*.mexmaca64" -exec spctl --add {} \;
But received the error:
This operation is no longer supported. Please see the man page for more inform.

macOS no longer supports spctl to add trust for .mexmaca64 files. Is there an alternative method to 
allow MATLAB to load these files?Is there an updated guide or recommended steps for running SPM12 
on macOS Sequoia15.1 (Apple Silicon)? Specifically for ensuring MEX files are compiled and trusted.

I would greatly appreciate any guidance or recommendations to resolve these issues.

GeQi

Hi,

I am carrying out a full factorial group level analysis with covariates, however I want to run a 
model which also looks at the interaction between one of the factors and a covariate. To see this 
effect, do I need to define a new contrast and how should I define it?

Many thanks

Jedidah

We are seeking for highly motivated candidates for 1 Postdoc and 1 PhD position in the Action 
Recognition and Concepts Group at CIMeC (Center for Mind/Brain Sciences), University of Trento, 
Italy. The research project will focus on an MEG-based dynamic extension to representational 
similarity analysis (dynamic RSA) that we have recently developed in our lab to investigate 
predictive representations of dynamic events. 



We're looking for applicants who:

• Have a strong drive to pursue a career in scientific research

• Possess independent and critical thinking skills

• Excel in collaborative teamwork

• Have a background in cognitive neuroscience (preferably M/EEG or fMRI, MVPA/RSA) and strong 
programming skills (preferably Matlab, or Python)

• Have experience in action / biological motion perception (ideally in generating point light 
displays or avatars) or in action execution



At CIMeC, you'll have access to cutting-edge research facilities, such as:

• A brand new MEGIN TRIUX neo MEG system

• A 3T MRI Siemens Prisma

• TMS, EEG, and combined TMS-EEG setups

• Human intracranial stereotactic EEG

• Eye-tracking systems

• Kinematic recording systems



All equipment is dedicated 100% to research purposes, providing you with the ideal environment for 
testing your research questions. As a member of our lab and of the wider CIMeC community, you will 
be part of an international community of students and researchers in a vibrant scientific 
environment. The working language is English. Our lab enjoys numerous international collaborations, 
and we offer ample opportunities to engage with the broader scientific community through 
conferences, workshops, and international meetings, supported by research funding attracted by our 
lab.



Living in Trentino offers a unique combination of natural beauty and cultural richness. Situated 
among stunning landscapes between the Dolomites and Lake Garda, it provides a serene setting where 
you can appreciate nature alongside various cultural activities and sports. Trentino is undoubtedly 
one of the most beautiful regions in Italy, offering an exceptional quality of life alongside your 
academic pursuits.



The Postdoc position will be for 2 years (potentially extendable), start date is flexible but 
ideally in spring/summer 2025. The PhD position will start in fall 2025, the deadline to apply will 
be in June 2025 (find more information on CIMeC’s doctoral program here).

If you are thrilled to contribute to our research in cognitive neuroscience, please send an 
informal inquiry, including a CV and a brief statement of research interests, to 
moritz.wurm@unitn.it. We look forward to hearing from you!



Best wishes,

Moritz Wurm

Hi Max



the phenomenon described by Chris is well described (with simple code to play with) in this paper: 
Misconceptions in the use of the General Linear Model applied to functional MRI: a tutorial for 
junior neuro-imagers 
(https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2014.00001/full)



cyril



technical note: from an estimation perspective (raw effect size) Chris is right you can turn a 
design of a 2-sample t-test into a 1-sample, but from an inference perspective (stat testing) this 
is different because the error term (ie the variance estimate) is different (paired t-test uses the 
variance of the difference, 2-samples the pooled variance)



On 17/11/2024 08.00, Phillips Christophe wrote:
Hi Max,

The GLM is so because it captures the mean effect of your conditions before/after across the 
subjects and the subject mean effect. And thus the contrast only applies over the &st 2 columns.
The 2-sample t-test could also be turned into a 1-sample t-test of each pair difference but there 
is certainly NO smoothing applied during the GLM estimation.
If you looked at the mean of the pair difference, it should be the same as the contrast [1 -1].

Best,
Chris


From: Max McLachlan <mclachlan2@WISC.EDU>
Sent: 16 November 2024 01:56
To: Phillips Christophe <C.Phillips@ULIEGE.BE>
Subject: Re: Contrast Vector for Paired T-test
 
Hi Chris,

Thanks for the help, I thought I would have to write something else in for the remainder of the 
vector. I did notice that the beta images that a paired t-test outputs seem a little different than 
if I just directly subtract the images myself - do you know if the software implicitly applies any 
smoothing beforehand?

Thanks,
Max

-- 
Dr Cyril Pernet, PhD, OHBM fellow, SSI fellow
Neurobiology Research Unit, 
Building 8057, Blegdamsvej 9
Copenhagen University Hospital, Rigshospitalet
DK-2100 Copenhagen, Denmark

wamcyril@gmail.com
https://zcal.co/cpernet
https://cpernet.github.io/
https://orcid.org/0000-0003-4010-4632

Hi Max,

The GLM is so because it captures the mean effect of your conditions before/after across the 
subjects and the subject mean effect. And thus the contrast only applies over the &st 2 columns.
The 2-sample t-test could also be turned into a 1-sample t-test of each pair difference but there 
is certainly NO smoothing applied during the GLM estimation.
If you looked at the mean of the pair difference, it should be the same as the contrast [1 -1].

Best,
Chris


From: Max McLachlan <mclachlan2@WISC.EDU>
Sent: 16 November 2024 01:56
To: Phillips Christophe <C.Phillips@ULIEGE.BE>
Subject: Re: Contrast Vector for Paired T-test
 
Hi Chris,

Thanks for the help, I thought I would have to write something else in for the remainder of the 
vector. I did notice that the beta images that a paired t-test outputs seem a little different than 
if I just directly subtract the images myself - do you know if the software implicitly applies any 
smoothing beforehand?

Thanks,
Max


Hi all,
When using Slice Overlay from the main spm interface under Render, how can I change the color of 
the Contours (White in here around an ROI on the back of the brain)?
The word white autopulate by it self. When I change it to Red or Blue, it goes to the next step 
(the colormap step), but the result is the same, a white countour.
How can I specify the color of the contour and can I make it transparent?
Thank you all for any help.
Nabil

Hi again,

I'd like to apply the deformation to a 4D nifti file in native space. The small script I wrote 
based on CAT12's code only works for a 3D image. Would someone have a way to apply the 
transformation from native to affine space to a 4D nifti file ? And is there a simpler way using 
SPM or CAT12 functions ?
From: David Romascano <David.Romascano@unige.ch>
Sent: Friday, November 15, 2024 3:18 PM
To: Ashburner, John <j.ashburner@ucl.ac.uk>; SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>
Subject: Re: [EXTERNAL] Re: SHOOT template from CAT12 segmentations
 
Good afternoon,

I double checked, and I have the latest versions for both spm and cat12. I also made sure the 
headers of the original images had not been changed, saving their md5sums before running cat12, and 
checking it was still the same afterwards, which they were (CAT12 creates an n* image and my guess 
is that it uses it as input so that header changes don't affect the original image).

I did manage to get what I wanted though. I modified the code in cat_io_writenii.m to save the 
transf variable when running CAT12 segmentation (at line 381, when writing the DARTEL outputs). The 
transf variable contains the matrices that are used to reslice volumes from native to affine space, 
through spm_slice_vol and spm_write_plane. I wrote a small script that loads the transformation and 
applies it to an image in native space. If I apply the y_rp1*_affine deformation to the new images 
in affine space, I get averages that are crisp and align well with the SHOOT template.

There might be another way, but this is the best I managed to get with my limited knowledge about 
SPM and CAT12. Let me know if you have any other suggestions.

Here's the short script in case someone would like to have a look. A side note here, this works 
with native data with 1mm isotropic voxels. If you have native data that gets resampled by CAT12, 
you'll need to interpolate your data before reslicing it to the affine space (currently implemented 
in cat_run_job1639.m, lines 450-528).

load('transf.mat');
input_filename = 'sub-001_ses-1_T1w.nii';  % <- image in native space
[FF, ff, ext] = fileparts(input_filename);
resliced_filename = fullfile(FF, ['r' ff '_affine' ext]);
%
% If your data is interpolated by CAT12, implement the interpolation step here, similar to lines 
450-528 in cat_run_job1639.m
%
% Read input info
input_vol = spm_vol(input_filename);
% Extract data values in native space
Y = spm_read_vols(input_vol);
% Create output vol
output_vol = struct('fname', resliced_filename,
                                         'dim',transf.odim,...
                                         'dt', input_vol.dt,...
                                         'pinfo',input_vol.pinfo,...
                                         'mat', transf.mat);
output_vol = spm_create_vol(output_vol);
N = nifti(output_vol.fname);
N.mat = transf.mat;
N.mat0 = transf.mat0;
create(N)
for i=1:transf.odim(3)
    tmp  = spm_slice_vol(double(Y) ,transf.M*spm_matrix([0 0 i]),transf.odim(1:2),[1,NaN]);
    output_vol = spm_write_plane(output_vol,tmp,i);
end

Best regards,
David

From: David Romascano <david.romascano@unige.ch>
Sent: Thu, 7 Nov 2024 17:24:38 +0000
To: Ashburner, John <j.ashburner@ucl.ac.uk>; SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>
Subject: Re: [EXTERNAL] Re: SHOOT template from CAT12 segmentations


Hi again,

I don't think I have changed anything, I took nii.gz files from dcm2niix outputs I saved in a bids 
directory, and untarred them as nii files for processing with SPM. I selected the 15 native T1 
files in CAT12 Segmentation tool and ran it with the Affine option for the DARTEL export.

When you say you didn't have any issue, you mean that you applied the y_rp1*_affine deformations to 
several native T1 images ? In my data, individually warped T1s do look ok-ish, but there's a slight 
misalignement between subjects, about 2-3 voxels, which makes the average image look blurry. This 
is not the case when I apply the deformation to rp1*_affine.nii images.

Will double check everything and rerun Cat12 and SHOOT from the start to be sure, and come back at 
you. Thanks for your support,
David

From: Ashburner, John <j.ashburner@ucl.ac.uk>
Sent: Thursday, November 7, 2024 5:53 PM
To: David Romascano <David.Romascano@unige.ch>; SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>
Subject: [EXTERNAL] Re: Re: SHOOT template from CAT12 segmentations
 
It looks like the matrices in the headers are as they should be, in which case I'm not really sure 
what might have gone wrong.

Might you have done something that involves changing the headers of the original images after they 
were segmented?  For example, of you coregistered them to match some fMRI scans or reoriented them 
in some other way.  The fact that the CheckReg thing seems to have worked suggests that this may 
not be the case.

Are you using the most up to date version of SPM?  I've just tried to replicate the problem, but it 
worked fine for me.

Bye for now,
-John

From: David Romascano <David.Romascano@unige.ch>
Sent: 07 November 2024 15:19
To: Ashburner, John <j.ashburner@ucl.ac.uk>; SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>
Subject: Re: [EXTERNAL] Re: SHOOT template from CAT12 segmentations
 
Hi John,

Thanks for the quick reply ! Indeed the S-form matrices are the same for all subjects:

   -1.5000         0         0   85.5000
         0    1.5000         0 -121.5000
         0         0    1.5000  -73.5000
         0         0         0    1.0000

and the Q-form matrices do differ from subject to subject. Opening a native T1 and the 
corresponding CAT12 rp1*_affine.nii in CheckReg shows misaligned scans at first, but after running 
your code in the matlab console and clicking on different locations, the two images do overlap 
correctly.

What does this mean regarding the deformation field ? Should I create a new nifti file with the 
S-form replaced by the Q-form, and apply the deformation field to it ? This sounds like a way to 
'reslice' a native image into CAT12's affine space, which is what I was looking for.

From: Ashburner, John <j.ashburner@ucl.ac.uk>
Sent: Thursday, November 7, 2024 3:55 PM
To: SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>; David Romascano <David.Romascano@unige.ch>
Subject: [EXTERNAL] Re: SHOOT template from CAT12 segmentations
 
Because you say "Applying the deformation to the rp1*_affine.nii images does work", it sounds like 
there may be a slight difference in the headers of the rp*_affine.nii from what would be expected 
by SPM.

When "imported" rc*.nii are generated via SPM's segmentation, the headers contain two matrices.  
The main one (the S-form matrix) encodes the orientations of the images relative to all the other 
"imported" images so that they seem to be in approximate alignment.  The other matrix (Q-form 
matrix) encodes the orientation relative to the original scan.

The following code allows you to see the matrices.


P=spm_select(Inf,'^rp1.*_affine\.nii');

disp('These S-form matrices should all be the same:')
for i=1:size(P,1)
    Nii=nifti(P(i,:));
    disp(Nii.mat)
end

disp('These Q-form matrices should all differ from each other:')
for i=1:size(P,1)
    Nii=nifti(P(i,:));
    disp(Nii.mat0)
end


I'm not sure how CAT12 deals with the headers. In principle, if the S-form matrix is replaced by 
the Q-form matrix, then CheckReg should show the images in alignment with the original scan.  You 
could see this by running CheckReg, selecting the original scan and one of the rp*_affine.nii . 
Then if you copy/paste the following into MATLAB and click somewhere in the images, you should (in 
principle) see the images in alignment with each other.

global st
st.vols{2}.mat = st.vols{2}.private.mat0


If this doesn't work, you might need to consult with Christian G.

All the best,
-John






From: SPM (Statistical Parametric Mapping) <SPM@JISCMAIL.AC.UK> on behalf of David Romascano 
<0000f1bab762ae17-dmarc-request@JISCMAIL.AC.UK>
Sent: 07 November 2024 13:49
To: SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>
Subject: [SPM] SHOOT template from CAT12 segmentations
 
⚠ Caution: External sender


Hi experts !

I want to warp images that are in subject/native space to a common space with as much GM overlap as 
possible. I segmented original (native) T1 images using CAT12, created a SHOOT template with the 
rp1*_affine and rp2*_affine images, and applied the deformations to other MRI images that are 
aligned with the native T1 (same field of view, voxel size, bbox, origin, etc...) .  But somehow 
the warped images don't overlap. I summarize what I tried below, but feel free to suggest another 
approach if you have a better way to achieve this.

I ran CAT12 segmentation with the following relevant options:
    Volumes: 15 native T1 weighted images
    Voxel size for normalized images: 1.5 mm
    No surface and thickness estimation
    No ROI processing
    GM/WM:
        Native space: Yes
        Modulated normalized: No
        DARTEL export: Affine
    Bias, noise, and global intensity  corrected T1 image
        Normalized: Yes
    No Jacobian determinant
    Inverse+Forward deformation field

I then ran SHOOT (create Template) with the following options:
    Images: the 15 rp1*_affine.nii images created by CAT12
    Images: the 15 rp2*_affine.nii images created by CAT12

I then tried using SHOOT's "Write Normalized" tool with the following options:
    SHOOT template: tried both leaving empty (to avoid MNI normalization), and specifying the 
Template_4.nii file created by SHOOT in the previous step.
    Deformation fields: the 15 y_rp1*_affine_Template.nii files created in the previous step
    Images: the 15 native T1 images used as input for CAT12
    Voxel size: NaNs
    Bounding box: NaNs
    Preserve: no modulation
    No smoothing

If I concatenate the warped native T1 images, there's quite some misalignement between subjects. 
The average image looks blurry. I applied the deformation to the p1 images in native space (p1* 
images) and averaged them, which gave me a map that looks blurred and far from the nice and crisp 
Template_4.nii generated by SHOOT. Also tried to apply the deformation field through SPM -> Spatial 
-> Normalise tool, but the images don't overlap either.

Applying the deformation to the rp1*_affine.nii images does work though. So I guess the deformation 
warps images in the affine space to template space. Is there a way to reslice an image in native 
space to the rp1*_affine.nii space, so that I can apply the deformation field afterwards ?

Things also work if I create the SHOOT template from the segmentations in native space (p1* and p2* 
images), and apply the deformation to images in native space. But according to the documentation in 
CAT12, using the rp1*_affine.nii as inputs for SHOOT should give better results, which probably 
means better GM overlap.

Thanks in advance and best regards,
David


Hi all, 

Please see below information on new Research Assistant and Postdoctoral Researcher positions 
available in Oxford, UK. 
Please be in touch with CV/cover letter if interested.

Research Assistant
Postdoctoral Researcher

Best wishes,
Laurel


Laurel S. Morris, Ph.D. she/her

Associate Professor  

Department of Psychiatry

Icahn School of Medicine at Mount Sinai

One Gustave L. Levy Place

New York, NY 10029

https://labs.icahn.mssm.edu/morrislab/


Dear Tim, Marko,

Thanks for the great help. Getting the right input for the spm_uc function indeed fixed it and now 
I have the exact same threshold as in the gui.

Regards,
Mathijs


Hi Ben,

The most up to date version of SPM is always available on GitHub (https://github.com/spm/spm). 
While there will be official calendar releases, the team aims to respond rapidly to any bugs found 
on GitHub so that the community has instant access to the most up to date version which was 
previously not possible when we used subversion for development

best,
Tim

Hello,

The resel count is a 4 element vector which is why the result is so far off. See equation 3.2 and 
3.3 here(https://pubmed.ncbi.nlm.nih.gov/20408186/)
for details on what needs to be entered. Also SPM will select the minimum height threshold of 
bonferroni and RFT to determine the height threshold. The correct usage would be something like

spm_uc(0.05,[1,4046],'T',[1,1,1,1961.5],1,20000)

where R has 4 elements and the 20000 represents the number of voxels

Hi Max,

The 1st 2 columns of your design matrix should be modelling the before and after treatment 
condition across your subjects, while the rest of the design will capture the "subject mean effect" 
for each of the subjects.
Thus, you contrast will be c = [1 -1] to test for scan_A > scan_B across your subjects.
Use c =[-1 1] if your hypothesis goes the other way. Or use an F-test with c = [1 -1] if you want 
to look for any effect, positive or negative, of the treatment.

Best,
Chris

Hi everyone!

Fairly new to SPM here. I ran an experiment where each of 20 subjects had a before and after 
treatment scan - so two scans total for each subject. I'm running a paired t-test factorial design. 
I'm having trouble with writing the correct contrast vector - I want to see group-level trends in 
the within-subject difference images - so basically a one sample t-test of the within-subject 
difference images. Is there a way to write that contrast starting from a paired t-test? Or is the 
best way just to make the difference images beforehand and run a one sample factorial design? Thank 
you!

I am looking for a Post-Doctoral Researcher at the initial stages (post-PhD and no more than 2 
years and half after obtaining their PhD). The applicants should have obtained a PhD, and have an 
overall interest in object recognition, potentially focusing on object-related features like shape, 
texture material and surface properties, and/or object-related action. I am particularly interested 
in researchers with strong expertise in fMRI, and in particular decoding and multivariate 
approaches. Good programming skills, great communication and mentoring skills, and a great command 
of English are a plus.

The selected applicant will work with me (Jorge Almeida) but will also benefit from the lively 
academic environment and research groups we are currently building in the Psychology Department of 
the University of Coimbra, Portugal (Jason Fischer, Joana Carvalho, Alfonso Caramazza, etc). The 
projects will relate to my work on object and mid-level processing. Below are some examples:

Mahon, B. Z., & Almeida, J. (2024). Reciprocal interactions among parietal and occipito-temporal 
representations support everyday object-directed actions. Neuropsychologia, 198, 108841. 
https://doi.org/10.1016/j.neuropsychologia.2024.108841

Almeida, J., Fracasso, A., Kristensen, S., Valério, D., Bergström, F., Chakravarthi, R., Tal, Z., & 
Walbrin, J. (2023). Neural and behavioral signatures of the multidimensionality of manipulable 
object processing. Communications biology, 6(1), 940. https://doi.org/10.1038/s42003-023-05323-x

Walbrin, J., & Almeida, J. (2021). High-Level Representations in Human Occipito-Temporal Cortex Are 
Indexed by Distal Connectivity. The Journal of neuroscience : the official journal of the Society 
for Neuroscience, 41(21), 4678–4685. https://doi.org/10.1523/JNEUROSCI.2857-20.2021

The position is for 2 to 3 years, and the salary is the standard Post-Doctoral pay-scale in 
Portugal (net value 1800 euros per month; this is a competitive salary for the cost of living in 
Portugal and especially in Coimbra). Start time should be as soon as possible.

The Proaction Lab is currently well-funded as we have a set of on-going funded projects including a 
Starting Grant ERC to Jorge Almeida, a major European ERA Chair project to Jorge Almeida and 
Alfonso Caramazza, and other projects. We have access to a 3T MRI scanner with a 32-channel coil, 
to a 7T scanner (in collaboration with a site outside of Portugal), to tDCS, and to a fully set 
psychophysics lab. We have a 256 ch EEG, motion tracking and eyetracking on site. We also have a 
science communication office dedicated to the lab.

Finally, the University of Coimbra is a 700-year-old University and has been selected as a UNESCO 
world Heritage site. Coimbra is one of the liveliest university cities in the world, and it is a 
beautiful city with easy access to the beach and mountain.

You should apply as soon as you can. If interested send an email to jorgecbalmeida@gmail.com, with 
a CV, and motivation/scientific proposal letter. 



Hi,



this could be due to Bonferroni correction, which SPM does in the background and chooses it if it 
is stricter. You may want to check what happens if you set a global NOBONF variable to 1 and then 
try again.



Cheers
Marko



Dear List,

apologies if this is an old hat - searching the list didn't yield any quick answer.

https://www.fil.ion.ucl.ac.uk/spm/software/ states that

'The current version is SPM12, released 1st October 2014 and last updated 13th January 2020. The 
next version is scheduled for release in Spring 2024.'

Any updates on the planned release?

Thanks!

Ben

Hi all,

I was trying to get the FWE corrected threshold of first-level fMRI results in a script using 
spm_uc. However, I have difficulty getting the same threshold that is provided when displaying the 
results using the gui. When using the gui I get a height threshold of T=4.57 for FWE p<0.05, df = 
[1,4046], resels = 1961.5. However, when I run:

spm_uc(0.05,[1,4046],'T',1961.5,1)

I get a height threshold of 4.0494. What am I missing?

Kind regards,
Mathijs Raemaekers


Dear Colleagues, 

The Schools of Engineering (STI), Life Sciences (SV) and Computer and Communication Sciences (IC) 
at EPFL invite applications for a tenure-track assistant faculty position to hold the Medtronic 
chair in Neuromodulation within the Neuro X Institute.

Areas of interest include, but are not limited to, adaptive neuromodulation, minimally invasive 
techniques, ultrasound and endovascular applications, AI-based approaches, targeted pain 
modulation, and neuroinflammation.

The EPFL Neuro X institute fosters interdisciplinary research and is committed to lead 
technological advances and translating this innovation from preclinical research to the clinical 
environment. We anticipate the new faculty member will be able to build scientific interactions 
within the EPFL community, neighbouring institutions, and with partner hospitals along the Lemanic 
Arc.

The successful candidate will strive to develop excellence in teaching and mentoring undergraduate 
and graduate students. The faculty member will operate in state-of-the-art labs across EPFL 
campuses in Geneva (anticipated home campus), Lausanne, Fribourg and/or Sion.

A doctorate will be required at the starting date. The candidate is expected to develop an 
independent and competitive research program in a multidisciplinary environment. The faculty member 
will supervise their own PhD students and engage with researchers in related fields across the EPFL 
campus. The successful candidate must have a strong commitment to excellence in teaching and 
contribute to education programs at the undergraduate and graduate levels.

The EPFL environment is multilingual and multicultural. EPFL offers internationally competitive 
salaries, generous research support, significant start-up resources, an outstanding research 
infrastructure, and close ties to the Swiss Federal government as well as the international policy 
hub in Geneva. Academics in Switzerland enjoy many research funding opportunities and an 
exceptionally high standard of living.

The application package should include the following documents in pdf format: cover letter 
including a statement of motivation; curriculum vitae; publication list; research statement (max 3 
pages); statement of teaching interests (max 1 page); as well as the names and contact of three to 
five references who are ready to supply a letter upon request.

Application deadline: 15 December 2024

Applications should be uploaded to the EPFL recruitment page:

https://facultyrecruiting.epfl.ch/position/57671683  

Inquiries can be addressed to:
Prof. Stéphanie P. Lacour
Director of the Neuro X Institute
Chair of the Search Committee
E-mail:  inx-search@epfl.ch

Further information on EPFL and Neuro X is available at http://www.epfl.ch and 
http://neuro-x.epfl.ch

EPFL is an equal opportunity employer and family friendly university. It is committed to increasing 
the diversity of its faculty. It strongly encourages women to apply.

Dear Peter,

 

Thank you very much for your response and the script! I've been experimenting quite a bit with the 
data and trying out several models. I have a few more questions regarding this, and I've also 
encountered a new error message since I started testing new models. Unfortunately I haven't found 
anything on the internet about this. I would therefore ask you for help again.

 

1. I currently have a total of 13 VOIs. To generate these for all subjects, I used the Batch Editor 
for one participant and then adapted the script to add more subjects (Batch Editor - Util - Volume 
of Interest). When generating the VOIs, I select "Effects of interest" under "adjust data," as 
indicated on the SPM homepage. In the "old" SPM12, I enter "NaN" to adjust for all conditions. In 
the Development Version of SPM, as I understand from the Batch Editor, I need to enter "eye(2)" 
since I have two conditions. However, no matter what I enter, the Development Version does not 
accept anything in this field. Therefore, I have continued to use SPM12 to generate the VOIs.

 

2. Next, I specify the DCM models for each participant. We assume that condition 1 (Task) has an 
influence on the network, while condition 2 (Baseline) does not. My specifications for the fully 
connected model are as follows:

 

%%%%%



nSubjects = 23; % Number of subjects

subjectIDs = {'01', '02', …, '22', '23'};

nRegions = 13; % Number of VOIs

nu = 2; % Number of conditions

TR = 3.4;

TE = 0.0216;

 

% A-Matrix

a = ones(nRegions, nRegions); % All regions are connected with each other

 

% B-Matrix

b = zeros(nRegions, nRegions, nu); % Initialization of modulatory connectivity

b(:, :, 1) = 1; % Condition 1 affects all connections

b(:, :, 2) = 0; % Condition 2 does not affect any connections

 

% C-Matrix

c = zeros(nRegions, nu); % Initialization of the C-Matrix

c(:, 1) = 1; % Condition 1 affects all regions

 

% D-Matrix

d = zeros(nRegions, nRegions, 0); % No non-linear effects

 

% Path to subjects data

path_to_subject_data = '/Volumes/XY/subjects_folder';

 

for iSub = 1:nSubjects

    subjectID = subjectIDs{iSub}; % ID of the current subject

 

    % Path to the SPM.mat file for this subject

    spmFile = fullfile(path_to_subject_data, subjectID, 'glm', 'SPM.mat');

    load(spmFile);

 

    % Load VOI files for the current subject

    voifiles = {

        fullfile(path_to_subject_data, subjectID, 'glm', 'VOI_1_1.mat'),

        fullfile(path_to_subject_data, subjectID, 'glm', 'VOI_2_1.mat'),

        …,

        fullfile(path_to_subject_data, subjectID, 'glm', 'VOI_12_1.mat'),

        fullfile(path_to_subject_data, subjectID, 'glm', 'VOI_13_1.mat')

    };

 

    % Define conditions

    cond(1).name = 'AM';

    cond(1).spmname = {'AM'};

 

    cond(2).name = 'Baseline';

    cond(2).spmname = {'Baseline'};

 

    % Specify structure for DCM

    s = struct();

    s.name = ['DCM_' subjectID '_model_1'];

    s.cond = cond;

    s.delays = repmat(TR/2, 1, nRegions);

    s.TE = TE;

    s.nonlinear = false;

    s.two_state = false;

    s.stochastic = false;

    s.centre = true;

    s.induced = 0;

    s.a = a;

    s.b = b;

    s.c = c;

    s.d = d;

 

    % Specify DCM for the current subject

    DCM = spm_dcm_specify(SPM, voifiles, s);

 

    % Specify and save storage location for DCM

    save(fullfile(path_to_subject_data, subjectID, 'glm', ['DCM_' subjectID '_model_1.mat']), 
'DCM');

    clear SPM voifiles s DCM;

end



 %%%%





The other 13 models differ only in that condition 1 has an influence on a specific VOI, for 
example:



%%%%%



% C-Matrix

c = zeros(nRegions, nu); % Initialization of the C-Matrix

c(5, 1) = 1; % VOI 5 is influenced by condition 1



 %%%%%



When I run the scripts, I do not get an error message, but I do receive a warning each time:

 

```

> In spm_dcm_specify_ui (line 248)

> In spm_dcm_specify (line 139)

> In g_DCM_model_1 (line 74) 

Warning: VOIs were adjusted using different F-contrasts. This may not have been intentional.

> In spm_dcm_specify_ui (line 106)

> In spm_dcm_specify (line 139)

> In g_DCM_model_1 (line 74) 

Warning: Condition AM was excluded using an effects of interest F-contrast during VOI extraction, 
but was included in the DCM. Please revisit VOI extraction.

```

 

 - As I understand it, I can simply ignore this warning, or am I mistaken?

 

 - Additionally, I specify the delays as `s.delays = repmat(TR/2, 1, nRegions);`, which defaults to 
½ TR. Does this make sense in my case? Our TR is quite long at 3.4 seconds...

 

3. Finally, I estimate the models and create the group model "GCM.mat". I have done this before 
with fewer VOIs and fewer models—without any issues. However, with 13 VOIs, 14 models, and 23 
subjects, I get the following error message at the very end:

 

```

EM:(-): 10     F: 3.354e+00 dF predicted: 4.498e-03  actual: -9.092e-03 (34.99 sec)

EM:(-): 11     F: 3.354e+00 dF predicted: 6.113e-04  actual: -1.714e-03 (34.45 sec)

EM:(-): 12     F: 3.354e+00 dF predicted: 8.278e-05  convergence

 

Please ensure your models are nested

10-Nov-2024 14:46:57 - Failed  'DCM estimation'

Output argument "RCM" (and possibly others) not assigned a value in the execution of the 
"spm_dcm_bmr" function.

In file "/Applications/spm/spm_dcm_bmr.m", function "spm_dcm_bmr" at line 68.

In file "/Applications/spm/config/spm_cfg_dcm_est.m", function "spm_run_dcm_est" at line 366.

 

The following modules did not run:

Failed: DCM estimation

```

 

I couldn't find anything about this error online. To troubleshoot, I have reduced the script and 
run it multiple times:

 

- With all 23 subjects and model 1, plus 4-5 "nested" models. Regardless of which models were 
included, everything ran without issues.

- With all models but only the first two subjects—also without any issues.

 

I am currently testing the script with different participant groups to see if it might be a 
specific participant causing the issue.

 

However, could it also be that the number of VOIs or the number of included models is too large for 
the number of subjects? Or could it be an issue with memory or available resources? I am working on 
a Mac with 32GB of RAM, an Apple silicon processor (Apple M2 Pro), and I am using MATLAB 2023b for 
Intel Macs.

 

Apologies for the long email—and once again, thank you very much for your help!!!

 

Best

Christine



---------------------------------------------
Dr. med. Dipl. Biol. Christine Kindler

Fachärztin für Neurologie
Klinik für Alterspsychiatrie und Kognitive Störungen
Universitätsklinikum Bonn
Venusberg-Campus 1
53127 Bonn

Von: Zeidman, Peter <peter.zeidman@ucl.ac.uk>
Gesendet: Montag, 28. Oktober 2024 09:23:28
An: Kindler, Dr. Christine; SPM@JISCMAIL.AC.UK
Betreff: RE: [SPM] DCM Group Analysis
 
Dear Christine
Thank you for getting in touch. My initial guess is that the "Specify Group" batch expects all the 
subjects to have the same number of fMRI volumes, which is not a good assumption and is not the 
case here.

I aim to confirm whether this is indeed the issue and create a fix to SPM this week.

In the meantime, if you need a faster resolution and you are happy with scripting, you could write 
a script to generate all your subjects' DCM, rather than using the batch. I paste some example code 
below, from the help text at the top of spm_dcm_specify.m .  This requires the SPM Dev version from 
Github. You would put this code in a for loop to generate DCMs for each subject.

Best
Peter

Example for a task-based experiment:
-------------------------------------------------------------------------
n   = 3;    % number of regions
nu  = 2;    % number of inputs (experimental conditions)
TR  = 2;    % volume repetition time (seconds)
TE  = 0.03; % echo time (seconds)

% Experimental conditions to include from the SPM.
% To see the conditions' names, load your SPM.mat into the workspace and
% inspect SPM.Sess(s).U.name, where s is the session (run) number.
cond = struct();
cond(1).name    = 'Condition1'; % desired name for the condition
cond(1).spmname = {'c1','c2'};  % (optional) corresponding name(s) of
                                % conditions in the SPM.mat file, see
                                % SPM.Sess(s).U.name. If multiple names
                                % are provided then they will be combined
                                % by binarizing the regressors and performing
                                an 'OR' operation.

cond(2).name    = 'Condition2';
cond(2).spmname = {'c3','c4'};

% Connectivity matrices
a  = ones(n,n);
b  = zeros(n,n,nu);
c  = ones(n,nu);
d  = zeros(n,n,0);

s = struct();
s.name       = 'test';
s.cond       = cond;
s.delays     = repmat(TR/2, 1, n);
s.TE         = TE;
s.nonlinear  = false;
s.two_state  = false;
s.stochastic = false;
s.centre     = true;
s.induced    = 0;
s.a          = a;
s.b          = b;
s.c          = c;
s.d          = d;
DCM = spm_dcm_specify(SPM,xY,s);


Tips:
- You can either select which experimental conditions to include by using
the s.cond structure, as illustrated above, or by specifying a matrix
s.u(i,j), which sets whether to include regressor j of condition i from 
the SPM design matrix. If there are no parametric regressors, then j
will always equal one.

- xY is a cell array of strings containing the filenames of the VOIs to
include.

-----Original Message-----
From: SPM (Statistical Parametric Mapping) <SPM@JISCMAIL.AC.UK> On Behalf Of Christine Kindler
Sent: 24 October 2024 09:40
To: SPM@JISCMAIL.AC.UK
Subject: [SPM] DCM Group Analysis

⚠ Caution: External sender


Dear SPM experts,

I am reaching out because I have encountered an issue with my DCM group analysis and I am unsure 
how to proceed.

Briefly about the design of the analysis: For each subject, I specified and estimated a GLM on a 
single-subject level with one session, two contrasts, six motion parameters as regressors, and a TR 
of 3.4 seconds – all without issues. From this, I generated a total of 8 VOIs. Subsequently, I 
specified and estimated three different DCM-models for one of the subjects at the individual level– 
again, without any issues. Now, I would like to run a group analysis via the Batch Editor → DCM → 
DCM specification → DCM for fMRI → specify group to determine which of my three models best 
explains the data. For "Full DCM," I entered the first fully connected model of the single subject, 
and for "Alternative DCMs," the other two models that were also generated for this individual 
subject. For "SPM.mat files," I included the GLM.mat files of all the subjects, and for "Regions of 
Interest," I specified each VOI of each of the subjects.

When I try to run the batch, I get the following error message:
"Input period and output period do not match. Number of inputs=2912, input dt=0.21, input 
period=618.80. Number of outputs=196, output dt=3.40, output period=666.40."

In the DCM specification for individual participants, a `DCM.U.dt` of 0.2125 seconds is used. My 
understanding is that the total input duration (618.80 seconds) does not match the total duration 
of the BOLD time series (666.40 seconds).

I suspect that the issue might be related to the temporal resolution of the input data (U), which 
could be due to the GLM design or the specification of the stimulus onsets. I have checked 
`DCM.U.dt` for all models, and it seems to be consistently 0.2125 seconds across all models, but it 
evidently does not match the TR of the BOLD data.

Could you help me understand where the value of 0.2125 seconds for `DCM.U.dt` comes from and how I 
could resolve this issue so that the inputs and outputs are better aligned?

Thank you very much for your help.

Best wishes,
Christine



Vorstand: Univ.-Prof. Dr. Bernd Weber – komm. Vorstandsvorsitzender und Dekan der Med. Fakultät • 
Clemens Platzköster – Kaufmännischer Direktor und stellv. Vorstandsvorsitzender • Univ.-Prof. Dr. 
Alexandra Philipsen – komm. Ärztliche Direktorin • Univ.-Prof. Dr. Johannes Oldenburg – komm. 
stellv. Ärztlicher Direktor • Alexander Pröbstl – Vorstand Pflege und Patientenservice • 
Aufsichtsratsvorsitzender: Univ.-Prof. Dr. Heinz Reichmann Anstalt öffentlichen Rechts • 
Gerichtsstand Bonn • Finanzamt Bonn Innenstadt • Ust-IdNr.: DE 811 917 555 • Bank: Sparkasse 
KölnBonn • BIC COLSDE33 • IBAN DE52 3705 0198 0010 6506 61

Dear colleagues,

For the tenth time, the Lund University Humanities Lab, Lund, Sweden, offers a three-day intensive 
course in eye-tracking methodology: A practical introduction to eye tracking. An important part of 
the course comprises hands-on exercises, where participants will work individually with 
state-of-the-art eye tracker hardware and software.

The course takes place November 27-29, 2024 at the Lund University Humanities Lab, in the Digital 
Classroom:
https://www.humlab.lu.se/facilities/eye-tracking/the-digital-classroom/

For more information about the course, visit the course webpage:
https://www.humlab.lu.se/education/commissioned-education/


Please feel free to share the link with people who you think would be interested.

Best wishes,
Marcus Nyström and Diederick Niehorster
Lund University Humanities Lab

Dear Paul

You can create a batch following my previous post (see also attached illustration) and then 
generate a MATLAB script:
Select View --> Show .m Code.

You can then use this script to automate your analysis. If you need to perform multiple 2nd level 
analyses, create a loop:

spm('defaults','fmri');
spm_jobman('initcfg');

for i=1:N
    matlabbatch ... = ... (place inputs here depending on the i-th step)
    spm_jobman('run',matlabbatch);
    clear matlabbatch
end

Alternatively, you can calculate classical and Bayesian contrasts without matlabbatch system. See 
spm_contrasts.m or this script:
https://github.com/Masharipov/BPI_2021/blob/main/simulations/scripts/bayesian_inference.m

I will write about the instability in personal communication.

Regarding Han & Park (2018) paper, there are two important notes:

1) Authors selected "T-contrast" option after Bayesian model estimation, but discussed and reported 
logBF in the paper. However, if you select "T-contrast" option, you will get Log Posterior Odds 
(LPO).
LPOs and logBFs are not exactly the same: Log BF = Log Posterior Odds + Log Prior Odds.
When the T-contrast option is selected, SPM calculates posterior probability of finding the effect 
higher than effect size (ES) threshold. Next, SPM calculates LPO as log(PPM/(1-PPM)).
When the "F-contrast" option is selected, SPM uses the Savage-Dickey approximation to the Bayes 
Factor.

2) Authors stated that the default ES threshold at 2nd level is equal to one Cohen’s d: " In terms 
of ES, square root of SPM.PPM.Cb can be understood as Cohen’s d = 1". Consequentially, they 
reported results for small, medium, and large Cohen’s d ES thresholds. However, these thresholds 
(0.2*sqrt(SPM.PPM.Cb), 0.5*sqrt(SPM.PPM.Cb), and 0.8*sqrt(SPM.PPM.Cb)) cannot be referred to 
Cohen's d values.
At the 1st lvl of analysis, the default ES threshold = 0.1% (percent signal change relative to the 
mean whole-brain “baseline” signal).
At the 2nd lvl, the default ES threshold = 1 prior SD of the contrast across the whole brain. 
Typically, 1 prior SD is about 0.1% (if you convert raw beta values to PSC). One prior SD can be 
calculated as the square root of SPM.PPM.Cb. Thus, according to the authors, Cohen’s d equals to 
mean posterior unstandardized effect size (raw beta value or converted to PSC) in the i-th voxel 
(cBeta(i)) divided by prior SD:
d(i) = cBeta(i) / priorSD
PriorSD is the constant value calculated based on information from the whole brain (i.e. it is the 
same for all voxels). In fact, to calculate Cohen’s d, we need to divide by cBetai by posterior 
standard deviation in the i-th voxel (postSD(i)):
d(i) = cBeta(i) / postSD(i)
This means, that to apply Cohen’s d threshold to cBeta images, we need to use different ES 
thresholds for each voxel depending on the posterior SD in the i-th voxel (rather than a constant 
ES threshold equals to one prior SD over all voxels). For example, if we want to use an ES 
threshold γ = 0.8 Cohen’s d, then for i-th voxel with postSD(i) = 0.1% the unstandardized ES 
threshold will be 0.08%. But for j-th voxel with half as much postSD(j) = 0.05% the unstandardized 
ES threshold will be two times smaller = 0.04%.

Best
Ruslan

Hi everyone

Last chance to sign up for our new 1-day seminar Python for R Users, running Nov 13 with professor 
Rebecca Barter from the Division of Epidemiology at the University of Utah School of Medicine. For 
researchers who are familiar with R, especially within the tidyverse ecosystem, transitioning to 
Python offers a strategic advantage for academic research. Python's versatility and broad 
applicability across a huge range of scientific fields make it a crucial tool for complex data 
analysis and model building. To facilitate this, the seminar is designed to help PhD students, 
academics, and professional researchers leverage their existing R knowledge to quickly gain 
proficiency in Python, focusing on translating concepts and techniques familiar in R to the Python 
environment. Participants will gain a robust understanding of Python's libraries and data 
structures, enabling them to integrate Python into their research workflows efficiently and expand 
their analytical capabilities, including with Python's substantial toolkits for machine learning 
and deep learning such as Scikit-learn and Keras (for machine learning and deep learning).

Sign up today and don't miss out on this unique opportunity to easily transition from R to Python!


Best wishes

Michael Zyphur
Director
Institute for Statistical and Data Science
instats.org

Zhi, you are absolutely right! Thank you!

Jim

On Tue, Nov 5, 2024 at 10:34 PM Zhi Li <lizhi.psych@gmail.com> wrote:
Thank you very much, Jim. Yes, I am using slice timing in temporal correction. However, based on 
other sources, it appears the timing should be specified in milliseconds rather than seconds.

Best,

Zhi


On Tue, 5 Nov 2024 at 05:42, James Lee <jleeslc@gmail.com> wrote:
Zhi,

Yes, the slice timing processing is different, and remember that you need to specify it for all 
slices, but the basic pattern will repeat.
So, for Siemens data processed in SPM with 48 slices and mb=4 my batch script has:

ord = [0.6375 0 0.425 0.0725 0.495 0.1425 0.565 0.2825 0.7075 0.355 0.7775 0.2125];

slice_order = repmat(ord,1,4); % repeat the order 4 times for 48 slices

matlabbatch{1}.spm.temporal.st.so = slice_order;



I also want to comment on multiband factor and the number of coil channels available in data 
acquisition. Some investigators at our institution got carried away and used a multiband factor or 
8 when the coil only had 20 channels. The data was useless.

In my experience the multiband factor that can be used successfully is related to the number of 
channels in this way:

With a 20 channel coil I get minimal artifacts with mb=4, but NOT with mb=6.
With a 32 channel coil I get minimal artifacts with mb=4 and mb=6, but NOT with mb=8.
WIth a 64 channel coil I get minimal artifacts with all three mb factors.

On this topic, I found the paper below instructive.

Hope this helps!

Jim

Which multiband factor should you choose for your resting-state fMRI study?
Risk, Murden et al, 
Neuroimage. 2021 Jul 1;234:117965. doi: 10.1016/j.neuroimage.2021.117965. Epub 2021 Mar 17.
PMID: 33744454

On Fri, Nov 1, 2024 at 8:03 AM Zhi Li <lizhi.psych@gmail.com> wrote:
Dear SPM experts,

I am currently processing task-based fMRI data acquired using multiband sequencing. Could you 
please clarify the key differences in preprocessing steps between multiband and single-band EPI 
data? Specifically, in SPM, I understand that slice order must be converted to timing in 
milliseconds for slice timing correction. Are there additional considerations unique to multiband 
data, especially for first-level GLM and DCM analyses? The manual seems to lack specific guidelines 
on this. Additionally, is multiband task fMRI data suitable for DCM analysis? I would be grateful 
for any recommendations or guidance.

Best,

Zhi Li

SPM Savants,

I am mystified by how spm_get_bf gets called when I calculate fmri statistics in batch mode, i.e. 
spm_jobman('run', matlabbatch), using spm12_7771.

If I use the spm gui for stats, spm_get_bf gets called from spm_fMRI_design, but I can't see the 
mechanism when I run in batch mode, and yet I know it works because if I modify spm_get_bf and run 
batch mode, the modifications come through.

Many Thanks!

Jim


Dear Ruslan

Thank you for your reply. My specific question was whether there was a way to programmatically 
select between classical and Bayesian contrasts like the GUI allows for models with both kinds of 
estimation. Having two separate models works is fine as a workaround.

I've been following this paper to get started:
https://doi.org/10.3389/fninf.2018.00001

I'll give yours a read.

I note your recommendation to roll back to v6906 for Bayesian estimation. Can you say more about 
the instability?

For some reason the list unlinked your reply from my OP, so here's the the permalink in the remote 
chance a third person is interested:
https://www.jiscmail.ac.uk/cgi-bin/wa-jisc.exe?A2=SPM;6992f703.2410

Best wishes,
Paul

On Fri, 8 Nov 2024 14:00:48 +0000, Masharipov Ruslan <masharipov@IHB.SPB.RU> wrote:

>Dear Paul
>
>You need to Specify 2nd level model and add four modules to the list using SPM batch editor:
>
>---------Classical inference---------
>1) Select SPM -> Stats -> Model estimation --> Select SPM.mat --> Select your SPM.mat file --> 
Method: Classical
>2) Select SPM -> Stats -> Contrast manager --> Select SPM.mat --> Dependency --> Select First 
Model estimation --> Define T and F contrasts
>
>---------Bayesian inference---------
>3) Select SPM -> Stats -> Model estimation --> Select SPM.mat --> Dependency --> Select First 
Model estimation --> Method: Bayesian 2nd-level
>4) Select SPM -> Stats -> Contrast manager --> Select SPM.mat --> Dependency --> Select SECOND 
Model estimation --> Define T and F contrast.
>
>Please note that T contrast in Bayesian inference refers to Log Posterior Odds (Bayesian Parameter 
Inference, BPI) and F contrast refers to Log Bayesian Factor (Bayesian Model Inference, BMI).
>Log BF = Log Posterior Odds + Log Prior Odds.
>
>If you select T contrast, you need to define the region of practical equivalence (interval null 
hypothesis).
>
>If you select F contrast, you will be using a point null hypothesis. This option is biased against 
null effects (you will not able to find evidence for null results, e.g. "not activated voxels").
>
>For more details, see this paper:
>https://doi.org/10.3389/fninf.2021.738342
>
>I recommend to use spm_reml.m function from SPM12 v6906 release for Bayesian model estimation, 
since this function produces unstable results in later releases.
>
>You can also try BayInf toolbox for SPM12, which allows you to find both (de)activated voxels, not 
activated voxels (high evidence for the null hypothesis) and low confidence voxels (insufficient 
data):
>https://github.com/IHB-IBR-department/bayesian_inference_toolbox
>
>
>Best
>Ruslan

Dear Luna

This may depend on several factors: 1) sPPI vs gPPI model, 2) mean centering vs no mean centering 
(depends on your SPM12 release), 3) co-activations may spuriously inflate FC estimates (e.g. PPI 
effects similar to simple activation effects).
For more details, see this paper:
https://www.nature.com/articles/s42003-024-07088-3

I suggest you use FIR task regression to remove co-activations prior to PPI analysis. You can also 
use gPPI model with FIR regressors (gPPI-FIR model).

Another important point to consider when performing task-modulated functional connectivity analysis 
is the HRF variability. In most cases, the HRF variability across subjects and brain regions is 
high. In case of high HRF variability, the most sensitive and specific method is BSC-LSS (sPPI/gPPI 
sensitivity is significantly reduced by HRF heterogeneity).

You can try task-modulated functional connectivity (TMFC) toolbox for SPM12 (it can be used for 
seed-to-voxel and ROI-to-ROI analysis; BSC-LSS and gPPI + FIR regression):
https://github.com/IHB-IBR-department/TMFC_toolbox


Best
Ruslan

Dear Paul

You need to Specify 2nd level model and add four modules to the list using SPM batch editor:

---------Classical inference---------
1) Select SPM -> Stats -> Model estimation --> Select SPM.mat --> Select your SPM.mat file --> 
Method: Classical
2) Select SPM -> Stats -> Contrast manager --> Select SPM.mat --> Dependency --> Select First Model 
estimation --> Define T and F contrasts

---------Bayesian inference---------
3) Select SPM -> Stats -> Model estimation --> Select SPM.mat --> Dependency --> Select First Model 
estimation --> Method: Bayesian 2nd-level
4) Select SPM -> Stats -> Contrast manager --> Select SPM.mat --> Dependency --> Select SECOND 
Model estimation --> Define T and F contrast.

Please note that T contrast in Bayesian inference refers to Log Posterior Odds (Bayesian Parameter 
Inference, BPI) and F contrast refers to Log Bayesian Factor (Bayesian Model Inference, BMI).
Log BF = Log Posterior Odds + Log Prior Odds.

If you select T contrast, you need to define the region of practical equivalence (interval null 
hypothesis).

If you select F contrast, you will be using a point null hypothesis. This option is biased against 
null effects (you will not able to find evidence for null results, e.g. "not activated voxels").

For more details, see this paper:
https://doi.org/10.3389/fninf.2021.738342

I recommend to use spm_reml.m function from SPM12 v6906 release for Bayesian model estimation, 
since this function produces unstable results in later releases.

You can also try BayInf toolbox for SPM12, which allows you to find both (de)activated voxels, not 
activated voxels (high evidence for the null hypothesis) and low confidence voxels (insufficient 
data):
https://github.com/IHB-IBR-department/bayesian_inference_toolbox


Best
Ruslan

Hi again,

I don't think I have changed anything, I took nii.gz files from dcm2niix outputs I saved in a bids 
directory, and untarred them as nii files for processing with SPM. I selected the 15 native T1 
files in CAT12 Segmentation tool and ran it with the Affine option for the DARTEL export.

When you say you didn't have any issue, you mean that you applied the y_rp1*_affine deformations to 
several native T1 images ? In my data, individually warped T1s do look ok-ish, but there's a slight 
misalignement between subjects, about 2-3 voxels, which makes the average image look blurry. This 
is not the case when I apply the deformation to rp1*_affine.nii images.

Will double check everything and rerun Cat12 and SHOOT from the start to be sure, and come back at 
you. Thanks for your support,
David

It looks like the matrices in the headers are as they should be, in which case I'm not really sure 
what might have gone wrong.

Might you have done something that involves changing the headers of the original images after they 
were segmented?  For example, of you coregistered them to match some fMRI scans or reoriented them 
in some other way.  The fact that the CheckReg thing seems to have worked suggests that this may 
not be the case.

Are you using the most up to date version of SPM?  I've just tried to replicate the problem, but it 
worked fine for me.

Bye for now,
-John

From: David Romascano <David.Romascano@unige.ch>
Sent: 07 November 2024 15:19
To: Ashburner, John <j.ashburner@ucl.ac.uk>; SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>
Subject: Re: [EXTERNAL] Re: SHOOT template from CAT12 segmentations
 
Hi John,

Thanks for the quick reply ! Indeed the S-form matrices are the same for all subjects:

   -1.5000         0         0   85.5000
         0    1.5000         0 -121.5000
         0         0    1.5000  -73.5000
         0         0         0    1.0000

and the Q-form matrices do differ from subject to subject. Opening a native T1 and the 
corresponding CAT12 rp1*_affine.nii in CheckReg shows misaligned scans at first, but after running 
your code in the matlab console and clicking on different locations, the two images do overlap 
correctly.

What does this mean regarding the deformation field ? Should I create a new nifti file with the 
S-form replaced by the Q-form, and apply the deformation field to it ? This sounds like a way to 
'reslice' a native image into CAT12's affine space, which is what I was looking for.

From: Ashburner, John <j.ashburner@ucl.ac.uk>
Sent: Thursday, November 7, 2024 3:55 PM
To: SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>; David Romascano <David.Romascano@unige.ch>
Subject: [EXTERNAL] Re: SHOOT template from CAT12 segmentations
 
Because you say "Applying the deformation to the rp1*_affine.nii images does work", it sounds like 
there may be a slight difference in the headers of the rp*_affine.nii from what would be expected 
by SPM.

When "imported" rc*.nii are generated via SPM's segmentation, the headers contain two matrices.  
The main one (the S-form matrix) encodes the orientations of the images relative to all the other 
"imported" images so that they seem to be in approximate alignment.  The other matrix (Q-form 
matrix) encodes the orientation relative to the original scan.

The following code allows you to see the matrices.


P=spm_select(Inf,'^rp1.*_affine\.nii');

disp('These S-form matrices should all be the same:')
for i=1:size(P,1)
    Nii=nifti(P(i,:));
    disp(Nii.mat)
end

disp('These Q-form matrices should all differ from each other:')
for i=1:size(P,1)
    Nii=nifti(P(i,:));
    disp(Nii.mat0)
end


I'm not sure how CAT12 deals with the headers. In principle, if the S-form matrix is replaced by 
the Q-form matrix, then CheckReg should show the images in alignment with the original scan.  You 
could see this by running CheckReg, selecting the original scan and one of the rp*_affine.nii . 
Then if you copy/paste the following into MATLAB and click somewhere in the images, you should (in 
principle) see the images in alignment with each other.

global st
st.vols{2}.mat = st.vols{2}.private.mat0


If this doesn't work, you might need to consult with Christian G.

All the best,
-John






From: SPM (Statistical Parametric Mapping) <SPM@JISCMAIL.AC.UK> on behalf of David Romascano 
<0000f1bab762ae17-dmarc-request@JISCMAIL.AC.UK>
Sent: 07 November 2024 13:49
To: SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>
Subject: [SPM] SHOOT template from CAT12 segmentations
 
⚠ Caution: External sender


Hi experts !

I want to warp images that are in subject/native space to a common space with as much GM overlap as 
possible. I segmented original (native) T1 images using CAT12, created a SHOOT template with the 
rp1*_affine and rp2*_affine images, and applied the deformations to other MRI images that are 
aligned with the native T1 (same field of view, voxel size, bbox, origin, etc...) .  But somehow 
the warped images don't overlap. I summarize what I tried below, but feel free to suggest another 
approach if you have a better way to achieve this.

I ran CAT12 segmentation with the following relevant options:
    Volumes: 15 native T1 weighted images
    Voxel size for normalized images: 1.5 mm
    No surface and thickness estimation
    No ROI processing
    GM/WM:
        Native space: Yes
        Modulated normalized: No
        DARTEL export: Affine
    Bias, noise, and global intensity  corrected T1 image
        Normalized: Yes
    No Jacobian determinant
    Inverse+Forward deformation field

I then ran SHOOT (create Template) with the following options:
    Images: the 15 rp1*_affine.nii images created by CAT12
    Images: the 15 rp2*_affine.nii images created by CAT12

I then tried using SHOOT's "Write Normalized" tool with the following options:
    SHOOT template: tried both leaving empty (to avoid MNI normalization), and specifying the 
Template_4.nii file created by SHOOT in the previous step.
    Deformation fields: the 15 y_rp1*_affine_Template.nii files created in the previous step
    Images: the 15 native T1 images used as input for CAT12
    Voxel size: NaNs
    Bounding box: NaNs
    Preserve: no modulation
    No smoothing

If I concatenate the warped native T1 images, there's quite some misalignement between subjects. 
The average image looks blurry. I applied the deformation to the p1 images in native space (p1* 
images) and averaged them, which gave me a map that looks blurred and far from the nice and crisp 
Template_4.nii generated by SHOOT. Also tried to apply the deformation field through SPM -> Spatial 
-> Normalise tool, but the images don't overlap either.

Applying the deformation to the rp1*_affine.nii images does work though. So I guess the deformation 
warps images in the affine space to template space. Is there a way to reslice an image in native 
space to the rp1*_affine.nii space, so that I can apply the deformation field afterwards ?

Things also work if I create the SHOOT template from the segmentations in native space (p1* and p2* 
images), and apply the deformation to images in native space. But according to the documentation in 
CAT12, using the rp1*_affine.nii as inputs for SHOOT should give better results, which probably 
means better GM overlap.

Thanks in advance and best regards,
David



Actually, this might be trickier than I thought. Replacing the S-form by the Q-form in the 
rp1*_affine volume makes it overlap with the native T1 image, but I think what I need is the 
opposite, to get the native T1 image to overlap with the rp1*_affine volume, so that I can apply 
the deformation to it.

Would you have a way to do this ?

From: David Romascano <David.Romascano@unige.ch>Sent: Thursday, November 7, 2024 4:19 PMTo: 
Ashburner, John <j.ashburner@ucl.ac.uk>; SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>Subject: Re: 
[EXTERNAL] Re: SHOOT template from CAT12 segmentations
 
Hi John,

Thanks for the quick reply ! Indeed the S-form matrices are the same for all subjects:

   -1.5000         0         0   85.5000
         0    1.5000         0 -121.5000
         0         0    1.5000  -73.5000
         0         0         0    1.0000

and the Q-form matrices do differ from subject to subject. Opening a native T1 and the 
corresponding CAT12 rp1*_affine.nii in CheckReg shows misaligned scans at first, but after running 
your code in the matlab console and clicking on different locations, the two images do overlap 
correctly.

What does this mean regarding the deformation field ? Should I create a new nifti file with the 
S-form replaced by the Q-form, and apply the deformation field to it ? This sounds like a way to 
'reslice' a native image into CAT12's affine space, which is what I was looking for.

From: Ashburner, John <j.ashburner@ucl.ac.uk>Sent: Thursday, November 7, 2024 3:55 PMTo: 
SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>; David Romascano <David.Romascano@unige.ch>Subject: 
[EXTERNAL] Re: SHOOT template from CAT12 segmentations
 
Because you say "Applying the deformation to the rp1*_affine.nii images does work", it sounds like 
there may be a slight difference in the headers of the rp*_affine.nii from what would be expected 
by SPM.

When "imported" rc*.nii are generated via SPM's segmentation, the headers contain two matrices.  
The main one (the S-form matrix) encodes the orientations of the images relative to all the other 
"imported" images so that they seem to be in approximate alignment.  The other matrix (Q-form 
matrix) encodes the orientation relative to the original scan.

The following code allows you to see the matrices.


P=spm_select(Inf,'^rp1.*_affine\.nii');

disp('These S-form matrices should all be the same:')
for i=1:size(P,1)
    Nii=nifti(P(i,:));
    disp(Nii.mat)
end

disp('These Q-form matrices should all differ from each other:')
for i=1:size(P,1)
    Nii=nifti(P(i,:));
    disp(Nii.mat0)
end


I'm not sure how CAT12 deals with the headers. In principle, if the S-form matrix is replaced by 
the Q-form matrix, then CheckReg should show the images in alignment with the original scan.  You 
could see this by running CheckReg, selecting the original scan and one of the rp*_affine.nii . 
Then if you copy/paste the following into MATLAB and click somewhere in the images, you should (in 
principle) see the images in alignment with each other.

global st
st.vols{2}.mat = st.vols{2}.private.mat0


If this doesn't work, you might need to consult with Christian G.

All the best,
-John






From: SPM (Statistical Parametric Mapping) <SPM@JISCMAIL.AC.UK> on behalf of David Romascano 
<0000f1bab762ae17-dmarc-request@JISCMAIL.AC.UK>Sent: 07 November 2024 13:49To: SPM@JISCMAIL.AC.UK 
<SPM@JISCMAIL.AC.UK>Subject: [SPM] SHOOT template from CAT12 segmentations
 
⚠ Caution: External sender

Hi experts !

I want to warp images that are in subject/native space to a common space with as much GM overlap as 
possible. I segmented original (native) T1 images using CAT12, created a SHOOT template with the 
rp1*_affine and rp2*_affine images, and applied the deformations to other MRI images that are 
aligned with the native T1 (same field of view, voxel size, bbox, origin, etc...) .  But somehow 
the warped images don't overlap. I summarize what I tried below, but feel free to suggest another 
approach if you have a better way to achieve this.

I ran CAT12 segmentation with the following relevant options:
    Volumes: 15 native T1 weighted images
    Voxel size for normalized images: 1.5 mm
    No surface and thickness estimation
    No ROI processing
    GM/WM:
        Native space: Yes
        Modulated normalized: No
        DARTEL export: Affine
    Bias, noise, and global intensity  corrected T1 image
        Normalized: Yes
    No Jacobian determinant
    Inverse+Forward deformation field

I then ran SHOOT (create Template) with the following options:
    Images: the 15 rp1*_affine.nii images created by CAT12
    Images: the 15 rp2*_affine.nii images created by CAT12

I then tried using SHOOT's "Write Normalized" tool with the following options:
    SHOOT template: tried both leaving empty (to avoid MNI normalization), and specifying the 
Template_4.nii file created by SHOOT in the previous step.
    Deformation fields: the 15 y_rp1*_affine_Template.nii files created in the previous step
    Images: the 15 native T1 images used as input for CAT12
    Voxel size: NaNs
    Bounding box: NaNs
    Preserve: no modulation
    No smoothing

If I concatenate the warped native T1 images, there's quite some misalignement between subjects. 
The average image looks blurry. I applied the deformation to the p1 images in native space (p1* 
images) and averaged them, which gave me a map that looks blurred and far from the nice and crisp 
Template_4.nii generated by SHOOT. Also tried to apply the deformation field through SPM -> Spatial 
-> Normalise tool, but the images don't overlap either.

Applying the deformation to the rp1*_affine.nii images does work though. So I guess the deformation 
warps images in the affine space to template space. Is there a way to reslice an image in native 
space to the rp1*_affine.nii space, so that I can apply the deformation field afterwards ?

Things also work if I create the SHOOT template from the segmentations in native space (p1* and p2* 
images), and apply the deformation to images in native space. But according to the documentation in 
CAT12, using the rp1*_affine.nii as inputs for SHOOT should give better results, which probably 
means better GM overlap.

Thanks in advance and best regards,
David



Ce message est envoyé depuis une adresse extérieure à l’UNIGE, soyez vigilant-es (expéditeur, 
pièces jointes).
This message is sent from an address outside UNIGE, be careful (sender, content).

Hi John,

Thanks for the quick reply ! Indeed the S-form matrices are the same for all subjects:

   -1.5000         0         0   85.5000
         0    1.5000         0 -121.5000
         0         0    1.5000  -73.5000
         0         0         0    1.0000

and the Q-form matrices do differ from subject to subject. Opening a native T1 and the 
corresponding CAT12 rp1*_affine.nii in CheckReg shows misaligned scans at first, but after running 
your code in the matlab console and clicking on different locations, the two images do overlap 
correctly.

What does this mean regarding the deformation field ? Should I create a new nifti file with the 
S-form replaced by the Q-form, and apply the deformation field to it ? This sounds like a way to 
'reslice' a native image into CAT12's affine space, which is what I was looking for.

From: Ashburner, John <j.ashburner@ucl.ac.uk>
Sent: Thursday, November 7, 2024 3:55 PM
To: SPM@JISCMAIL.AC.UK <SPM@JISCMAIL.AC.UK>; David Romascano <David.Romascano@unige.ch>
Subject: [EXTERNAL] Re: SHOOT template from CAT12 segmentations
 
Because you say "Applying the deformation to the rp1*_affine.nii images does work", it sounds like 
there may be a slight difference in the headers of the rp*_affine.nii from what would be expected 
by SPM.

When "imported" rc*.nii are generated via SPM's segmentation, the headers contain two matrices.  
The main one (the S-form matrix) encodes the orientations of the images relative to all the other 
"imported" images so that they seem to be in approximate alignment.  The other matrix (Q-form 
matrix) encodes the orientation relative to the original scan.

The following code allows you to see the matrices.


P=spm_select(Inf,'^rp1.*_affine\.nii');

disp('These S-form matrices should all be the same:')
for i=1:size(P,1)
    Nii=nifti(P(i,:));
    disp(Nii.mat)
end

disp('These Q-form matrices should all differ from each other:')
for i=1:size(P,1)
    Nii=nifti(P(i,:));
    disp(Nii.mat0)
end


I'm not sure how CAT12 deals with the headers. In principle, if the S-form matrix is replaced by 
the Q-form matrix, then CheckReg should show the images in alignment with the original scan.  You 
could see this by running CheckReg, selecting the original scan and one of the rp*_affine.nii . 
Then if you copy/paste the following into MATLAB and click somewhere in the images, you should (in 
principle) see the images in alignment with each other.

global st
st.vols{2}.mat = st.vols{2}.private.mat0


If this doesn't work, you might need to consult with Christian G.

All the best,
-John



The Multimodal Neuroimaging Group of Prof. Dr. Thilo van Eimeren at the University Hospital Cologne 
cordially invites applications for

 

1 PhD position (f/m/d)

in the field of Multimodal Neuroimaging

 

funded for 3 years (salary according to TV-L13: PhD 65%)

starting as early as possible

 

Our group (visit us on https://mmni.de/) currently looks for a highly motivated and qualified PhD 
candidate with a background in neuroscience or related fields. The candidate will mainly work on a 
project focusing on the impact of striatal dopamine loss and the potential compensatory effect of 
vagus nerve stimulation on motor motivation as well as the role of motor reserve in patients with 
Parkinson’s disease. In this project, we will apply a unique combination of behavioral and 
computational phenotyping and state-of-the-art molecular, functional, and structural neuroimaging 
technologies (e.g. functional MRI, dopamine transporter imaging, vagus nerve stimulation). The 
successful candidate will be involved in the preparation and conduct of the study and the analysis 
and publication of newly acquired and already existing datasets. The position provides the 
excellent opportunity to work in an interdisciplinary environment as part of the Collaborative 
Research Center “CRC 1451: Key mechanisms of motor control in health and disease” with an 
integrated Research Training Group.

The successful candidate will join a dynamic and open-minded lab with an excellent support 
structure (including a research coordinator). The lab, with long-lasting expertise in multimodal 
imaging of neurodegenerative diseases, is embedded in an excellent research environment with a 
close collaboration between the University Hospital Cologne, the Research Center Juelich, and the 
German Center for Neurodegenerative Diseases (DZNE). As a team, we are highly dedicated to 
supervision, teaching, and personal support and offer a high degree of flexibility including remote 
work.

Suitably qualified women will be given preferential consideration unless other applicants 
demonstrate superior qualification. We also welcome applications from disabled candidates, who will 
also be given preferential consideration over other applicants with comparable qualification.

 

Requirements for PhD position:

•          Master’s degree in neuroscience, medicine, psychology, biology or related field

•          Proficiency in English

•          Experience with programming languages and neuroimaging software packages is desired

 

Proficiency in German is important for the interaction with study participants. We reserve the 
right not to fill the advertised position.

Required documents for application:

Please submit your letter of motivation, CV, copies of transcripts, contact details of two 
potential referees as one single PDF document via email to Dr. Merle Hönig 
(merle.hoenig1@uk-koeln.de ). Application deadline: 26.1.2025





————————————————————



Die Arbeitsgruppe Multimodale Neurobildgebung von Prof. Dr. Thilo van Eimeren an der Uniklinik Köln 
lädt herzlich ein zur Bewerbung für



1 Doktorandenstelle (w/m/d)

auf dem Gebiet der Multimodalen Hirnbildgebung



Die Doktorandenstelle wird initial für 3 Jahre (Vergütung nach TV-L13: 65%) gefördert und soll 
schnellstmöglich besetzt werden.

Unsere Gruppe (besuchen Sie uns auf https://mmni.de/) sucht derzeit eine hoch motivierte und 
qualifizierte Person, die einen Hintergrund in den Neurowissenschaften oder verwandten Gebieten 
vorweisen kann. Die promovierende Person wird hauptsächlich an einem Projekt arbeiten, das sich mit 
den Auswirkungen des striatalen Dopaminverlusts und der möglichen kompensatorischen Funktion der 
Vagus-Nerv-Stimulation bei motivierten Bewegungsabläufen bei Parkinson Patienten sowie mit der 
Rolle der motorischen Reserve beschäftigt. In diesem Projekt werden wir eine einzigartige 
Kombination aus Verhaltens- und Computer-Phänotypisierungen und modernsten molekularen, 
funktionellen und strukturellen Neuroimaging-Technologien (z. B. funktionelle MRT, 
Dopamin-Transporter-Bildgebung, Vagus-Nerv-Stimulation) anwenden. Der/die erfolgreiche Kandidat/in 
wird an der Vorbereitung und Durchführung der Studie sowie an der Analyse und Veröffentlichung von 
neu gewonnenen und bereits vorhandenen Datensätzen beteiligt sein. Die Stelle bietet die 
hervorragende Möglichkeit, in einem interdisziplinären Umfeld als Teil des Sonderforschungsbereichs 
"SFB 1451: Schlüsselmechanismen der motorischen Kontrolle in Gesundheit und Krankheit" mit einem 
integrierten Graduiertenkolleg.

Die erfolgreiche Person wird Teil einer dynamischen und aufgeschlossenen Arbeitsgruppe mit einer 
ausgezeichneten Infrastruktur (einschließlich einer Forschungskoordinatorin). Die Arbeitsgruppe, 
mit langjähriger Expertise auf dem Gebiet der multimodalen Bildgebung bei neurodegenerativen 
Erkrankungen, ist Teil eines exzellenten Forschungsumfeld mit enger Zusammenarbeit zwischen der 
Universitätsklinik Köln, dem Forschungszentrum Jülich und dem Deutschen Zentrum für 
Neurodegenerative Erkrankungen (DZNE). Als Team sind wir sehr engagiert in der Betreuung, Lehre und 
persönlichen Unterstützung unserer Mitarbeitenden und bieten ein hohes Maß an Flexibilität 
einschließlich der Möglichkeit zur Telearbeit.

Bei gleicher Eignung werden Frauen bevorzugt berücksichtigt, sofern nicht andere Bewerber eine 
höhere Qualifikation nachweisen. Wir begrüßen auch Bewerbungen von Schwerbehinderten, die bei 
vergleichbarer Qualifikation ebenfalls bevorzugt berücksichtigt werden.

Voraussetzungen für die Doktorandenstelle:

•          Master-Abschluss in Neurowissenschaften, Medizin, Psychologie, Biologie oder einem 
verwandten Gebiet

•          Gute Sprachkenntnisse in Englisch

•          Erfahrung mit Programmiersprachen und Neuroimaging-Softwarepaketen ist erwünscht

Für die Stelle sind Deutschkenntnisse erforderlich. Wir behalten uns das Recht vor, die 
ausgeschriebenen Stellen nicht zu besetzen.

Erforderliche Unterlagen für die Bewerbung:

Bitte senden Sie Ihr Motivationsschreiben, Ihren Lebenslauf, Kopien von Zeugnissen, Kontaktdaten 
von zwei potentiellen Referenzpersonen als ein PDF-Dokument per E-Mail an Frau Dr. Merle Hönig 
(merle.hoenig1@uk-koeln.de ). Bewerbungsfrist: 26.1.2025

Hi all,

Two open PhD positions are offered:

Position 1:
 
Open position in the PhD research training group “Neuromodulation of Motor and Cognitive Function 
in Brain Health and Disease,” which focuses on advancing knowledge and technology in non-invasive 
neuromodulation to enhance motor and cognitive functions in stroke and Parkinson’s patients. PhD 
students will receive interdisciplinary training in neuromodulation techniques (e.g., brain 
stimulation, psychopharmacology, neurofeedback), neuroimaging, and methods for real-life 
assessment.

⚡️Project: Comparing transcranial alternating current stimulation (tACS) with EEG neurofeedback to 
evaluate their effects on EEG oscillations and motor performance. ⚡️Supervisors: Prof. Christoph 
Herrmann and Dr. Cornelia Kranczioch

🎓Applicant Profile:
* Master’s degree (or equivalent) in psychology, neuroscience, or related field by start date
* Experience with EEG neurofeedback or brain stimulation
* Skills in programming and data analysis (e.g., R, Matlab) preferred
* Location: Oldenburg

🌟We Offer:
* Payment per collective agreement (includes annual bonus, pension, asset-related benefits), 30 
days leave
* 4-year PhD funding option, induction support
* Flexible, family-friendly work environment; options for remote work
* Health promotion program, professional development, and support for early-career researchers

👩‍🔬Equal Opportunity: The University of Oldenburg prioritizes female candidates and applicants 
with disabilities when qualifications are equal.

📩Application: Send applications as a single PDF (cover letter, CV, publications, two referee 
contacts, academic certificates) by December 31, 2024, to rtgoffice@uol.de.

❓For questions, contact Prof. Herrmann (christoph.herrmann@uol.de) or Dr. Kranczioch 
(cornelia.kranczioch@uol.de).
 
Position 2:
 
open PhD position in our research group, “Neuromodulation of Motor and Cognitive Function in Brain 
Health and Disease,” which focuses on advancing knowledge and technology in non-invasive 
neuromodulation to enhance motor and cognitive functions in stroke and Parkinson’s patients. PhD 
students will receive interdisciplinary training in neuromodulation techniques (e.g., brain 
stimulation, psychopharmacology, neurofeedback), neuroimaging, and methods for real-life 
assessment.

⚡️Project: Motor imagery neurofeedback training at home for upper-limb motor recovery in stroke and 
associated changes in cortical motor-prefrontal functional connectivity. ⚡️Supervisors: Dr. 
Cornelia Kranczioch, Prof. Dr. Christiane Thiel, Prof. Dr. Christian Grefkes, Prof. Dr. med. 
Carsten Witt

🎓Applicant Profile:
* Master’s degree (or equivalent) in psychology, neuroscience, or related field by start date
* Experience in analyzing neuroimaging and / or neurophysiological data
* German proficiency: at least B2
* Skills in programming and data analysis (e.g., Python, Matlab) preferred
* Location: Oldenburg

🌟We Offer:
* Payment per collective agreement (includes annual bonus, pension, asset-related benefits), 30 
days leave
* 4-year PhD funding option, induction support
* Flexible, family-friendly work environment; options for remote work
* Health promotion program, professional development, and support for early-career researchers

👩‍🔬Equal Opportunity: The University of Oldenburg prioritizes female candidates and applicants 
with disabilities when qualifications are equal.

📩Application: Send applications as a single PDF (cover letter, CV, publications, two referee 
contacts, academic certificates) by January 5, 2025, to rtgoffice@uol.de.

❓For questions, contact Dr. Kranczioch (cornelia.kranczioch@uol.de).

Dear colleagues,
Applications are invited for a PhD position in Cognitive Neuroscience at the Institute of 
Neuroscience and Medicine (INM-3, Forschungszentrum Jülich).

For details of the position, please follow this link:
https://www.fz-juelich.de/de/karriere/stellenangebote/2024D-150
PhD position in Cognitive Neuroscience
Researchers at the Institute of Neuroscience and Medicine - Cognitive Neuroscience (INM-3) 
investigate the neural mechanisms underlying cognitive (dys-)function in healthy subjects and 
patients suffering from neurological and psychiatric disorders. Functional imaging (PET, MRI) and 
electrophysiological methods (EEG, TMS, tDCS) are combined with computational approaches.
www.fz-juelich.de


Best wishes
Simone Vossel


